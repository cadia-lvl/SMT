{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moses IS-EN EN-IS phrase þýðingarvél\n",
    "Sjá `README.md` til þess að keyra þetta vélrit (e. notebook).\n",
    "\n",
    "Í þessu vélriti eru gögn forunnin og Moses þýðingarkerfið notað til þess búa til tvö þýðingarkerfi, IS-EN og EN-IS.\n",
    "Það er gert ráð fyrir því að öll gögn séu aðgengileg undir `/work/data`. Sjá leiðbeiningar í `README.md` um hvernig það er gert með `docker` eða `singularity`.\n",
    "\n",
    "Í stuttu máli skiptist vélritið í eftirfarandi þætti:\n",
    "1. Samhliða og einhliða gögn undirbúin.\n",
    "1. Tungumála módel byggt fyrir EN og IS (KenLM).\n",
    "1. Texta skipt í þrjá hluta; train/val/test, fjöldi setninga í val/test er 3000/2000.\n",
    "1. Moses kerfið þjálfað með train hluta texta.\n",
    "1. Moses kerfið fínpússað með val hluta texta.\n",
    "1. Moses kerfið metið með BLEU mælingin á test hluta texta.\n",
    "\n",
    "Allar skrár og líkön eru raðað í skrána \"WORKING_DIR\" (sjá `README.md`).\n",
    "\n",
    "Safnið `corpus.py` skilgreinir föll og gagnategundir sem eru mikið nýttar hér."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/staff/haukurpj/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/staff/haukurpj/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict, Counter, OrderedDict\n",
    "import os\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import re\n",
    "from pprint import pprint\n",
    "import importlib\n",
    "from typing import List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import corpus.corpus as c\n",
    "\n",
    "importlib.reload(c)\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "working_dir = pathlib.Path('/work')\n",
    "data_dir = working_dir.joinpath('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's be sure that Moses is installed and the data is there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/moses\n",
      "/opt/moses_tools\n",
      "10\n",
      "bin  parice  risamalheild\r\n"
     ]
    }
   ],
   "source": [
    "print(os.getenv('MOSESDECODER'))\n",
    "print(os.getenv('MOSESDECODER_TOOLS'))\n",
    "print(int(os.getenv('THREADS')))\n",
    "!ls {data_dir}\n",
    "def get_modifier(modifiers):\n",
    "    if isinstance(modifiers, str):\n",
    "        return modifiers\n",
    "    return '-'.join(modifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bpe': None,\n",
      " 'bpe-final': PosixPath('/work/data/risamalheild/bpe-final.is'),\n",
      " 'cat': PosixPath('/work/data/risamalheild/cat.is'),\n",
      " 'final': PosixPath('/work/data/risamalheild/final.is'),\n",
      " 'kvistur': None,\n",
      " 'kvistur-final': PosixPath('/work/data/risamalheild/kvistur-final.is'),\n",
      " 'lm-blm': PosixPath('/work/data/risamalheild/lm-blm.is'),\n",
      " 'lm-blm-3': None,\n",
      " 'lower': None,\n",
      " 'placeholders': None,\n",
      " 'regexp': None,\n",
      " 'sent_fix': None,\n",
      " 'tok': None}\n",
      "{'bpe': PosixPath('/work/data/parice/train/bpe.en'),\n",
      " 'bpe-final': PosixPath('/work/data/parice/train/bpe-final.en'),\n",
      " 'bpe-length': PosixPath('/work/data/parice/train/bpe-length.en'),\n",
      " 'drop': PosixPath('/work/data/parice/train/drop.en'),\n",
      " 'final': PosixPath('/work/data/parice/train/final.en'),\n",
      " 'kvistur': None,\n",
      " 'kvistur-final': PosixPath('/work/data/parice/train/kvistur-final.en'),\n",
      " 'kvistur-length': PosixPath('/work/data/parice/train/kvistur-length.en'),\n",
      " 'length': PosixPath('/work/data/parice/train/length.en'),\n",
      " 'lm-blm': PosixPath('/work/data/parice/train/lm-blm.en'),\n",
      " 'lower': None,\n",
      " 'placeholders': None,\n",
      " 'regexp': PosixPath('/work/data/parice/train/regexp.en'),\n",
      " 'shuffle': None,\n",
      " 'tok': None,\n",
      " 'translated_en_is': None,\n",
      " 'translated_is_en': None}\n",
      "{'bpe': PosixPath('/work/data/parice/train/bpe.is'),\n",
      " 'bpe-final': PosixPath('/work/data/parice/train/bpe-final.is'),\n",
      " 'bpe-length': PosixPath('/work/data/parice/train/bpe-length.is'),\n",
      " 'drop': PosixPath('/work/data/parice/train/drop.is'),\n",
      " 'final': PosixPath('/work/data/parice/train/final.is'),\n",
      " 'kvistur': PosixPath('/work/data/parice/train/kvistur.is'),\n",
      " 'kvistur-final': PosixPath('/work/data/parice/train/kvistur-final.is'),\n",
      " 'kvistur-length': PosixPath('/work/data/parice/train/kvistur-length.is'),\n",
      " 'length': PosixPath('/work/data/parice/train/length.is'),\n",
      " 'lm-blm': PosixPath('/work/data/parice/train/lm-blm.is'),\n",
      " 'lower': None,\n",
      " 'placeholders': None,\n",
      " 'regexp': PosixPath('/work/data/parice/train/regexp.is'),\n",
      " 'shuffle': None,\n",
      " 'tok': None,\n",
      " 'translated_en_is': None,\n",
      " 'translated_is_en': None}\n"
     ]
    }
   ],
   "source": [
    "# List of stages in processing\n",
    "CAT = 'cat'\n",
    "SHUFFLE = 'shuffle'\n",
    "REGEXP = 'regexp'\n",
    "SENT_FIX = 'sent_fix'\n",
    "LOWER = 'lower'\n",
    "TOKENIZE = 'tok'\n",
    "PLACEHOLDERS = 'placeholders'\n",
    "LENGTH = 'length'\n",
    "DROP = 'drop'\n",
    "LM = 'lm-blm'\n",
    "LM_3 = 'lm-blm-3'\n",
    "TRAIN = 'train'\n",
    "TEST = 'test'\n",
    "VAL = 'val'\n",
    "BPE = 'bpe'\n",
    "KVISTUR = 'kvistur'\n",
    "FINAL = 'final'\n",
    "TRANSLATED_EN_IS = 'translated_en_is'\n",
    "TRANSLATED_IS_EN = 'translated_is_en'\n",
    "\n",
    "parice_dir = data_dir.joinpath('parice')\n",
    "rmh_dir = data_dir.joinpath('risamalheild')\n",
    "train_parice_dir = parice_dir.joinpath('train')\n",
    "test_parice_dir = parice_dir.joinpath('test')\n",
    "val_parice_dir = parice_dir.joinpath('val')\n",
    "\n",
    "!mkdir -p {train_parice_dir}\n",
    "!mkdir -p {test_parice_dir}\n",
    "!mkdir -p {val_parice_dir}\n",
    "\n",
    "pipeline = [\n",
    "    SHUFFLE,\n",
    "    LOWER, \n",
    "    REGEXP, \n",
    "    TOKENIZE,\n",
    "    PLACEHOLDERS,\n",
    "    LENGTH,\n",
    "    get_modifier((KVISTUR, FINAL)),\n",
    "    get_modifier((BPE, FINAL)),\n",
    "    get_modifier((KVISTUR, LENGTH)),\n",
    "    get_modifier((BPE, LENGTH)),\n",
    "    LM,\n",
    "    KVISTUR,\n",
    "    BPE,\n",
    "    FINAL,\n",
    "    DROP,\n",
    "    TRANSLATED_EN_IS,\n",
    "    TRANSLATED_IS_EN\n",
    "]\n",
    "rmh_stages = [\n",
    "    SENT_FIX,\n",
    "    LOWER,\n",
    "    REGEXP,\n",
    "    TOKENIZE,\n",
    "    PLACEHOLDERS,\n",
    "    KVISTUR,\n",
    "    get_modifier((KVISTUR, FINAL)),\n",
    "    get_modifier((BPE, FINAL)),\n",
    "    BPE,\n",
    "    LM,\n",
    "    LM_3,\n",
    "    FINAL,\n",
    "    CAT\n",
    "]\n",
    "parice_pipeline = [\n",
    "    CAT,\n",
    "    SENT_FIX,\n",
    "    SHUFFLE\n",
    "]\n",
    "\n",
    "# If we are not starting from scratch - we try to load all intermediary stages\n",
    "en_parice = c.pipeline_load(parice_dir, parice_pipeline, c.Lang.EN)\n",
    "is_parice = c.pipeline_load(parice_dir, parice_pipeline, c.Lang.IS)\n",
    "en_train = c.pipeline_load(train_parice_dir, pipeline, c.Lang.EN)\n",
    "is_train = c.pipeline_load(train_parice_dir, pipeline, c.Lang.IS)\n",
    "en_test = c.pipeline_load(test_parice_dir, pipeline, c.Lang.EN)\n",
    "is_test = c.pipeline_load(test_parice_dir, pipeline, c.Lang.IS)\n",
    "en_val = c.pipeline_load(val_parice_dir, pipeline, c.Lang.EN)\n",
    "is_val = c.pipeline_load(val_parice_dir, pipeline, c.Lang.IS)\n",
    "rmh = c.pipeline_load(rmh_dir, rmh_stages, c.Lang.IS)\n",
    "pprint(rmh)\n",
    "pprint(en_train)\n",
    "pprint(is_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stytta þjálfunarsetningar\n",
    "Moses á erfitt með að samstilla langar setningar. Við styttum þjálfunarsetningarnar svo einungis setningar sem eru eitt orð eða lengri upp að tölunni sem er skilgreint að neðan. Við höfum tekið eftir því að niðurstöðurnar sem við fáum með hámarkslengd (100) gefa ekki góðar niðurstöður.\n",
    "\n",
    "Þar sem við notum fall sem er skilgreint í Moses og tekur inn tvær skrár í einu fer nafnavenjan eitthvað á flakk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perl: warning: Setting locale failed.\n",
      "perl: warning: Please check that your locale settings:\n",
      "\tLANGUAGE = \"en_US:en\",\n",
      "\tLC_ALL = (unset),\n",
      "\tLC_CTYPE = \"C.UTF-8\",\n",
      "\tLANG = \"en_US.UTF-8\"\n",
      "    are supported and installed on your system.\n",
      "perl: warning: Falling back to the standard locale (\"C\").\n",
      "clean-corpus.perl: processing /work/data/parice/train/kvistur-final.en & .is to /work/data/parice/train/kvistur-length, cutoff 1-70, ratio 9\n",
      "..........(100000)..........(200000)..........(300000)..........(400000)..........(500000)..........(600000)..........(700000)..........(800000)..........(900000)..........(1000000)..........(1100000)..........(1200000)..........(1300000)..........(1400000)..........(1500000)..........(1600000)..........(1700000)..........(1800000)..........(1900000)..........(2000000)..........(2100000)..........(2200000)..........(2300000)..........(2400000)..........(2500000)..........(2600000)..........(2700000)..........(2800000)..........(2900000)..........(3000000)..........(3100000)..........(3200000)..........(3300000).......\n",
      "Input sentences: 3378149  Output sentences:  3315627\n"
     ]
    }
   ],
   "source": [
    "def corpus_shorten(path, path_out, lang_id_1, lang_id_2, min_length, max_length):\n",
    "    !{os.getenv('MOSESDECODER')}/scripts/training/clean-corpus-n.perl {path} {lang_id_1} {lang_id_2} {path_out} {min_length} {max_length}\n",
    "    return True\n",
    "\n",
    "IN = get_modifier((KVISTUR, FINAL))\n",
    "OUT = get_modifier((KVISTUR, LENGTH))\n",
    "\n",
    "path_out = is_train[FINAL].with_name(OUT)\n",
    "path = is_train[FINAL].parent.joinpath(IN)\n",
    "corpus_shorten(path, path_out, 'en', 'is', 1, 70)\n",
    "\n",
    "is_train[OUT] = is_train[FINAL].with_name(OUT).with_suffix('.is')\n",
    "en_train[OUT] = en_train[FINAL].with_name(OUT).with_suffix('.en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tungumála módel\n",
    "Við búum til KenLM mállíkan til þess að gefa okkur líkindi setninga. Til að flýta uppflettingum þá tungumála módelið samtímis kjörsniðið."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lm(path, out_path, order):\n",
    "    tmp_arpa = c.corpus_create_path(path, 'arpa')\n",
    "    !{os.getenv('MOSESDECODER')}/bin/lmplz --order {order} --temp_prefix {data_dir}/ --memory 70% < {path} > {tmp_arpa}\n",
    "    !{os.getenv('MOSESDECODER')}/bin/build_binary -S 70% {tmp_arpa} {out_path}\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 1/5 Counting and sorting n-grams ===\n",
      "Reading /work/data/parice/train/final.is\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Unigram tokens 45111359 types 557672\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\n",
      "Chain sizes: 1:6692064 2:32821854208 3:61540978688\n",
      "Statistics:\n",
      "1 557672 D1=0.654933 D2=1.04977 D3+=1.39709\n",
      "2 5194483 D1=0.744091 D2=1.10969 D3+=1.42352\n",
      "3 13501935 D1=0.704238 D2=1.17861 D3+=1.46824\n",
      "Memory estimate for binary LM:\n",
      "type     MB\n",
      "probing 364 assuming -p 1.5\n",
      "probing 396 assuming -r models -p 1.5\n",
      "trie    161 without quantization\n",
      "trie     94 assuming -q 8 -b 8 quantization \n",
      "trie    151 assuming -a 22 array pointer compression\n",
      "trie     85 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\n",
      "Chain sizes: 1:6692064 2:83111728 3:270038700\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
      "Chain sizes: 1:6692064 2:83111728 3:270038700\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 5/5 Writing ARPA model ===\n",
      "Name:lmplz\tVmPeak:92317988 kB\tVmRSS:20936 kB\tRSSMax:21556488 kB\tuser:27.6368\tsys:12.5545\tCPU:40.1913\treal:64.6351\n",
      "Reading /work/data/parice/train/arpa.is\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "SUCCESS\n",
      "=== 1/5 Counting and sorting n-grams ===\n",
      "Reading /work/data/parice/train/final.en\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Unigram tokens 48291472 types 329669\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\n",
      "Chain sizes: 1:3956028 2:32822806528 3:61542760448\n",
      "Statistics:\n",
      "1 329669 D1=0.716064 D2=0.994607 D3+=1.26719\n",
      "2 3577181 D1=0.725363 D2=1.07465 D3+=1.36989\n",
      "3 11255547 D1=0.680109 D2=1.14927 D3+=1.44098\n",
      "Memory estimate for binary LM:\n",
      "type     MB\n",
      "probing 283 assuming -p 1.5\n",
      "probing 304 assuming -r models -p 1.5\n",
      "trie    119 without quantization\n",
      "trie     68 assuming -q 8 -b 8 quantization \n",
      "trie    113 assuming -a 22 array pointer compression\n",
      "trie     62 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\n",
      "Chain sizes: 1:3956028 2:57234896 3:225110940\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
      "Chain sizes: 1:3956028 2:57234896 3:225110940\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 5/5 Writing ARPA model ===\n",
      "Name:lmplz\tVmPeak:92317988 kB\tVmRSS:13932 kB\tRSSMax:21514324 kB\tuser:24.3492\tsys:11.587\tCPU:35.9362\treal:55.1132\n",
      "Reading /work/data/parice/train/arpa.en\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "SUCCESS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_train[LM] = c.corpus_create_path(is_train[FINAL], LM)\n",
    "en_train[LM] = c.corpus_create_path(en_train[FINAL], LM)\n",
    "\n",
    "create_lm(is_train[FINAL], is_train[LM], order=3)\n",
    "create_lm(en_train[FINAL], en_train[LM], order=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BPE EN mállíkan\n",
    "Við þurfum að gera BPE mállíkan fyrir ensku. Við notum RMH+train fyrir IS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 1/5 Counting and sorting n-grams ===\n",
      "Reading /work/data/parice/train/bpe-final.en\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Unigram tokens 51851575 types 29977\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\n",
      "Chain sizes: 1:359724 2:32824055808 3:61545107456\n",
      "Statistics:\n",
      "1 29977 D1=0.405575 D2=0.967282 D3+=1.45389\n",
      "2 2821688 D1=0.67773 D2=1.06091 D3+=1.3985\n",
      "3 11237289 D1=0.659857 D2=1.14683 D3+=1.46034\n",
      "Memory estimate for binary LM:\n",
      "type     MB\n",
      "probing 258 assuming -p 1.5\n",
      "probing 274 assuming -r models -p 1.5\n",
      "trie     96 without quantization\n",
      "trie     50 assuming -q 8 -b 8 quantization \n",
      "trie     91 assuming -a 22 array pointer compression\n",
      "trie     44 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\n",
      "Chain sizes: 1:359724 2:45147008 3:224745780\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
      "Chain sizes: 1:359724 2:45147008 3:224745780\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 5/5 Writing ARPA model ===\n",
      "Name:lmplz\tVmPeak:92317988 kB\tVmRSS:6924 kB\tRSSMax:21512604 kB\tuser:25.4411\tsys:11.4173\tCPU:36.8583\treal:53.3393\n",
      "Reading /work/data/parice/train/arpa.en\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "SUCCESS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IN = get_modifier((BPE, FINAL))\n",
    "OUT = get_modifier((BPE, LM))\n",
    "\n",
    "en_train[OUT] = c.corpus_create_path(en_train[IN], OUT)\n",
    "\n",
    "create_lm(en_train[IN], en_train[OUT], order=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BPE IS mállíkan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IN = get_modifier((BPE, FINAL))\n",
    "OUT = get_modifier((BPE, CAT))\n",
    "\n",
    "rmh[OUT] = c.corpus_create_path(rmh[IN], OUT)\n",
    "c.corpora_combine((is_train[IN], rmh[IN]), rmh[OUT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN = get_modifier((BPE, CAT))\n",
    "OUT = get_modifier((BPE, LM))\n",
    "\n",
    "rmh[OUT] = c.corpus_create_path(rmh[IN], OUT)\n",
    "\n",
    "create_lm(rmh[IN], rmh[OUT], order=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kvistur IS mállíkan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IN = get_modifier((KVISTUR, FINAL))\n",
    "OUT = get_modifier((KVISTUR, CAT))\n",
    "\n",
    "rmh[OUT] = c.corpus_create_path(rmh[IN], OUT)\n",
    "c.corpora_combine((is_train[IN], rmh[IN]), rmh[OUT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 1/5 Counting and sorting n-grams ===\n",
      "Reading /work/data/risamalheild/kvistur-cat.is\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Unigram tokens 1686354880 types 2865258\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\n",
      "Chain sizes: 1:34383096 2:32812222464 3:61522919424\n"
     ]
    }
   ],
   "source": [
    "IN = get_modifier((KVISTUR, CAT))\n",
    "OUT = get_modifier((KVISTUR, LM))\n",
    "\n",
    "rmh[OUT] = c.corpus_create_path(rmh[IN], OUT)\n",
    "\n",
    "create_lm(rmh[IN], rmh[OUT], order=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sameina RMH og IS ParIce fyrir mállíkan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IN = get_modifier((FINAL))\n",
    "OUT = get_modifier((CAT))\n",
    "\n",
    "rmh[OUT] = c.corpus_create_path(rmh[IN], OUT)\n",
    "c.corpora_combine((is_train[IN], rmh[IN]), rmh[OUT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Búa til mállíkan að lengd 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 1/5 Counting and sorting n-grams ===\n",
      "Reading /work/data/risamalheild/cat.is\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Unigram tokens 1459492635 types 5833046\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\n",
      "Chain sizes: 1:69996552 2:32799834112 3:61499691008\n",
      "Statistics:\n",
      "1 5833046 D1=0.702775 D2=1.03479 D3+=1.32363\n",
      "2 84061923 D1=0.746733 D2=1.07179 D3+=1.34939\n",
      "3 332835285 D1=0.69458 D2=1.29804 D3+=1.52235\n",
      "Memory estimate for binary LM:\n",
      "type      MB\n",
      "probing 7782 assuming -p 1.5\n",
      "probing 8285 assuming -r models -p 1.5\n",
      "trie    3428 without quantization\n",
      "trie    2044 assuming -q 8 -b 8 quantization \n",
      "trie    3227 assuming -a 22 array pointer compression\n",
      "trie    1844 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\n",
      "Chain sizes: 1:69996552 2:1344990768 3:6656705700\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
      "Chain sizes: 1:69996552 2:1344990768 3:6656705700\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 5/5 Writing ARPA model ===\n",
      "Name:lmplz\tVmPeak:92363312 kB\tVmRSS:6200 kB\tRSSMax:27885800 kB\tuser:903.976\tsys:110.945\tCPU:1014.92\treal:1482.65\n",
      "Reading /work/data/risamalheild/arpa.is\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "SUCCESS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IN = get_modifier((CAT))\n",
    "OUT = get_modifier((LM))\n",
    "\n",
    "rmh[OUT] = c.corpus_create_path(rmh[IN], OUT)\n",
    "\n",
    "create_lm(rmh[IN], rmh[OUT], order=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prófa tungumála módel, það ættu ekki að vera nein óþekkt orð."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "þetta=408 2 -1.7515687\ter=108 3 -0.45247334\tflott=6918 3 -3.1758819\tíslensk=8107 2 -4.096338\tsetning=37795 2 -5.1012845\t,=25 2 -1.5267005\ter=108 3 -2.4015393\tþað=260 3 -1.3744248\tekki=184 3 -1.1722424\t?=97 3 -1.5301716\t</s>=2 3 -0.055470563\tTotal: -22.638096 OOV: 0\n",
      "Perplexity including OOVs:\t114.29012669708314\n",
      "Perplexity excluding OOVs:\t114.29012669708314\n",
      "OOVs:\t0\n",
      "Tokens:\t11\n",
      "Name:query\tVmPeak:7989284 kB\tVmRSS:4888 kB\tRSSMax:7973816 kB\tuser:0.003912\tsys:0.414758\tCPU:0.41867\treal:0.468255\n",
      "this=195 2 -1.8074161\tis=188 3 -0.68361896\ta=12 3 -1.0045757\tnice=1048 3 -2.8550868\tenglish=6319 1 -4.6239047\tsentence=2958 1 -5.020405\t,=6 2 -1.1387969\tright=170 2 -3.7610703\t?=94 3 -0.14322345\t</s>=2 3 -0.034358077\tTotal: -21.072456 OOV: 0\n",
      "Perplexity including OOVs:\t128.0105124034037\n",
      "Perplexity excluding OOVs:\t128.0105124034037\n",
      "OOVs:\t0\n",
      "Tokens:\t10\n",
      "Name:query\tVmPeak:310420 kB\tVmRSS:4792 kB\tRSSMax:294856 kB\tuser:0\tsys:0.038247\tCPU:0.038247\treal:0.0363867\n"
     ]
    }
   ],
   "source": [
    "def eval_sentence(lm_model, sentence):\n",
    "   !echo \"{sentence}\" | {os.getenv('MOSESDECODER')}/bin/query {lm_model}\n",
    "\n",
    "eval_sentence(rmh[LM], \"þetta er flott íslensk setning , er það ekki ?\")\n",
    "eval_sentence(en_train[LM], \"this is a nice english sentence , right ?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moses þjálfunar föll\n",
    "Næstu föll snúa að þjálfun Moses og annarra atriða sem þarf að hafa í huga. Þjálfunin tekur um 12 klst.\n",
    "Til þess að sjá framgang þjálfunar - sjá útprent þegar kallað er í föllin. Síðasta skrefið metur þýðingar Moses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_moses(model_dir, corpus, lang_from, lang_to, lang_to_lm, lm_order):\n",
    "    print(f'tail -f {model_dir}/training.out')\n",
    "    result = !{os.getenv('MOSESDECODER')}/scripts/training/train-model.perl -root-dir {model_dir} \\\n",
    "        -corpus {corpus} \\\n",
    "        -f {lang_from} -e {lang_to} \\\n",
    "        -alignment grow-diag-final-and -reordering msd-bidirectional-fe \\\n",
    "        -lm 0:{lm_order}:{lang_to_lm}:8 \\\n",
    "        -mgiza -mgiza-cpus {os.getenv('THREADS')} \\\n",
    "        -cores {os.getenv('THREADS')} \\\n",
    "        -external-bin-dir {os.getenv('MOSESDECODER_TOOLS')} &> {model_dir}/training.out\n",
    "    return model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_moses(model_dir, corpus_val_from, corpus_val_to, base_moses_ini):\n",
    "    print(f'tail -f {model_dir}/tune.out')\n",
    "    result = !{os.getenv('MOSESDECODER')}/scripts/training/mert-moses.pl \\\n",
    "        {corpus_val_from} \\\n",
    "        {corpus_val_to} \\\n",
    "        {os.getenv('MOSESDECODER')}/bin/moses {base_moses_ini} \\\n",
    "        --mertdir {os.getenv('MOSESDECODER')}/bin \\\n",
    "        --working-dir {model_dir} \\\n",
    "        --decoder-flags=\"-threads {os.getenv('THREADS')}\" &> {model_dir}/tune.out\n",
    "    return model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_binarisation(tuned_moses_ini,\n",
    "                         lm_path_in,\n",
    "                         lm_path_out,\n",
    "                         binarised_moses_ini,\n",
    "                         binarised_phrase_table,\n",
    "                         binarised_reordering_table):\n",
    "    !cp {tuned_moses_ini} {binarised_moses_ini}\n",
    "    !cp {lm_path_in} {lm_path_out}\n",
    "    # Adjust the path in the moses.ini file to point to the new files.\n",
    "    escaped_path_in = str(lm_path_in).replace(r'/', '\\/')\n",
    "    escaped_path_out = str(lm_path_out).replace(r'/', '\\/')\n",
    "    !sed -i 's/{escaped_path_in}/{escaped_path_out}/' {binarised_moses_ini}\n",
    "    # Adjust the path in the moses.ini file to point to the new files.\n",
    "    escaped_path = str(binarised_phrase_table).replace(r'/', '\\/')\n",
    "    !sed -i 's/PhraseDictionaryMemory/PhraseDictionaryCompact/' {binarised_moses_ini}\n",
    "    !sed -i 's/4 path=.*\\.gz input-factor/4 path={escaped_path} input-factor/' {binarised_moses_ini}\n",
    "    # Adjust the path in the moses.ini file\n",
    "    escaped_path = str(binarised_reordering_table).replace(r'/', '\\/')\n",
    "    !sed -i 's/0 path=.*\\.gz$/0 path={escaped_path}/' {binarised_moses_ini}\n",
    "    \n",
    "def binarise_phrase_table(base_phrase_table, binarised_phrase_table):\n",
    "    #Create the table\n",
    "    !{os.getenv('MOSESDECODER')}/bin/processPhraseTableMin \\\n",
    "        -in {base_phrase_table} \\\n",
    "        -nscores 4 \\\n",
    "        -out {binarised_phrase_table}\n",
    "    \n",
    "def binarise_reordering_table(base_reordering_table, binarised_reordering_table):\n",
    "    #Create the table\n",
    "    !{os.getenv('MOSESDECODER')}/bin/processLexicalTableMin \\\n",
    "        -in {base_reordering_table} \\\n",
    "        -out {binarised_reordering_table}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It only makes sense to filter the model when you know what text the system needs to translate.\n",
    "def filter_model(out_dir, moses_ini, corpus):\n",
    "    !{os.getenv('MOSESDECODER')}/scripts/training/filter-model-given-input.pl {out_dir} {moses_ini} {corpus}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_corpus(moses_ini, corpus, corpus_translated):\n",
    "    !{os.getenv('MOSESDECODER')}/bin/moses \\\n",
    "        -f {moses_ini} < {corpus} > {corpus_translated}\n",
    "    \n",
    "def eval_translation(corpus_gold, corpus_translated):\n",
    "    result = !{os.getenv('MOSESDECODER')}/scripts/generic/multi-bleu.perl -lc {corpus_gold} < {corpus_translated}\n",
    "    return result "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Byrja þjálfanir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tune_eval(LM,\n",
    "                    LM_ORDER,\n",
    "                    FROM,\n",
    "                    TO,\n",
    "                    MODIFIER,\n",
    "                    TRAIN_IN,\n",
    "                    VAL_IN,\n",
    "                    VAL_OUT,\n",
    "                    TEST_IN,\n",
    "                    TEST_OUT):\n",
    "    model_dir = working_dir.joinpath(f'{FROM}-{TO}-{MODIFIER}')\n",
    "    base_model_dir = model_dir.joinpath('base')\n",
    "    tuned_model_dir = model_dir.joinpath('tuned')\n",
    "    binarised_model_dir = model_dir.joinpath('binarised')\n",
    "    !mkdir -p {base_model_dir}\n",
    "    !mkdir -p {tuned_model_dir}\n",
    "    !mkdir -p {binarised_model_dir}\n",
    "\n",
    "    base_moses_ini = base_model_dir.joinpath('model/moses.ini')\n",
    "    base_phrase_table = base_model_dir.joinpath('model/phrase-table.gz')\n",
    "    base_reordering_table = base_model_dir.joinpath('model/reordering-table.wbe-msd-bidirectional-fe.gz')\n",
    "\n",
    "    tuned_moses_ini = tuned_model_dir.joinpath('moses.ini')\n",
    "\n",
    "    binarised_moses_ini = binarised_model_dir.joinpath('moses.ini')\n",
    "    binarised_phrase_table = binarised_model_dir.joinpath('phrase-table')\n",
    "    binarised_reordering_table = binarised_model_dir.joinpath('reordering-table')\n",
    "\n",
    "    # train\n",
    "    train_moses(base_model_dir, TRAIN_IN, FROM, TO, LM, lm_order=LM_ORDER)\n",
    "\n",
    "    # tune\n",
    "    tune_moses(tuned_model_dir, VAL_IN, VAL_OUT, base_moses_ini)\n",
    "\n",
    "    # binarise\n",
    "    !mkdir -p {binarised_model_dir}\n",
    "\n",
    "    lm_out = binarised_model_dir.joinpath('lm.blm')\n",
    "\n",
    "    prepare_binarisation(tuned_moses_ini, \n",
    "                         LM,\n",
    "                         lm_out, \n",
    "                         binarised_moses_ini, \n",
    "                         binarised_phrase_table, \n",
    "                         binarised_reordering_table)\n",
    "    binarise_phrase_table(base_phrase_table, binarised_phrase_table)\n",
    "    binarise_reordering_table(base_reordering_table, binarised_reordering_table)\n",
    "\n",
    "    # translate\n",
    "    translated = binarised_model_dir.joinpath(f'translated.{FROM}')\n",
    "\n",
    "    translate_corpus(binarised_moses_ini, TEST_IN, translated)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kvistur is-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tune_eval(LM = en_train[LM],\n",
    "                LM_ORDER = 3,\n",
    "                FROM = 'is',\n",
    "                TO = 'en',\n",
    "                MODIFIER = 'kvistur',\n",
    "                TRAIN_IN = is_train[FINAL].parent.joinpath(get_modifier((KVISTUR, LENGTH))),\n",
    "                VAL_IN = is_val[get_modifier((KVISTUR, FINAL))],\n",
    "                VAL_OUT = en_val[get_modifier((KVISTUR, FINAL))],\n",
    "                TEST_IN = is_test[get_modifier((KVISTUR, FINAL))],\n",
    "                TEST_OUT = en_test[get_modifier((KVISTUR, FINAL))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kvistur en-is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tune_eval(LM = rmh[get_modifier((KVISTUR, LM))],\n",
    "                LM_ORDER = 3,\n",
    "                FROM = 'en',\n",
    "                TO = 'is',\n",
    "                MODIFIER = 'kvistur',\n",
    "                TRAIN_IN = is_train[FINAL].parent.joinpath(get_modifier((KVISTUR, LENGTH))),\n",
    "                VAL_IN = en_val[get_modifier((KVISTUR, FINAL))],\n",
    "                VAL_OUT = is_val[get_modifier((KVISTUR, FINAL))],\n",
    "                TEST_IN = en_test[get_modifier((KVISTUR, FINAL))],\n",
    "                TEST_OUT = is_test[get_modifier((KVISTUR, FINAL))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BPE is-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tune_eval(LM = en_train[get_modifier((BPE, LM))],\n",
    "                LM_ORDER = 3,\n",
    "                FROM = 'is',\n",
    "                TO = 'en',\n",
    "                MODIFIER = 'bpe',\n",
    "                TRAIN_IN = is_train[FINAL].parent.joinpath(get_modifier((BPE, LENGTH))),\n",
    "                VAL_IN = is_val[get_modifier((BPE, FINAL))],\n",
    "                VAL_OUT = en_val[get_modifier((BPE, FINAL))],\n",
    "                TEST_IN = is_test[get_modifier((BPE, FINAL))],\n",
    "                TEST_OUT = en_test[get_modifier((BPE, FINAL))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BPE en-is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tune_eval(LM = rmh[get_modifier((BPE, LM))],\n",
    "                LM_ORDER = 3,\n",
    "                FROM = 'en',\n",
    "                TO = 'is',\n",
    "                MODIFIER = 'bpe',\n",
    "                TRAIN_IN = is_train[FINAL].parent.joinpath(get_modifier((BPE, LENGTH))),\n",
    "                VAL_IN = en_val[get_modifier((BPE, FINAL))],\n",
    "                VAL_OUT = is_val[get_modifier((BPE, FINAL))],\n",
    "                TEST_IN = en_test[get_modifier((BPE, FINAL))],\n",
    "                TEST_OUT = is_test[get_modifier((BPE, FINAL))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Laga Kvist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used options:\n",
      "\tText phrase table will be read from: /work/is-en-kvistur/base/model/phrase-table.gz\n",
      "\tOutput phrase table will be written to: /work/is-en-kvistur/binarised/phrase-table.minphr\n",
      "\tStep size for source landmark phrases: 2^10=1024\n",
      "\tSource phrase fingerprint size: 16 bits / P(fp)=1.52588e-05\n",
      "\tSelected target phrase encoding: Huffman + PREnc\n",
      "\tMaxiumum allowed rank for PREnc: 100\n",
      "\tNumber of score components in phrase table: 4\n",
      "\tSingle Huffman code set for score components: no\n",
      "\tUsing score quantization: no\n",
      "\tExplicitly included alignment information: yes\n",
      "\tRunning with 80 threads\n",
      "\n",
      "Pass 1/3: Creating hash function for rank assignment\n",
      "..................................................[5000000]\n",
      "..................................................[10000000]\n",
      "..................................................[15000000]\n",
      "..................................................[20000000]\n",
      "..................................................[25000000]\n",
      "..................................................[30000000]\n",
      "..................................................[35000000]\n",
      "....................\n",
      "\n",
      "Pass 2/3: Creating source phrase index + Encoding target phrases\n",
      "..................................................[5000000]\n",
      "..................................................[10000000]\n",
      "..................................................[15000000]\n",
      "..................................................[20000000]\n",
      ".........."
     ]
    }
   ],
   "source": [
    "LM = en_train['lm-blm']\n",
    "FROM = 'is'\n",
    "TO = 'en'\n",
    "MODIFIER = 'kvistur'\n",
    "TEST_IN = is_test[get_modifier((KVISTUR, FINAL))]\n",
    "TEST_OUT = en_test[get_modifier((KVISTUR, FINAL))]\n",
    "\n",
    "model_dir = working_dir.joinpath(f'{FROM}-{TO}-{MODIFIER}')\n",
    "base_model_dir = model_dir.joinpath('base')\n",
    "base_moses_ini = base_model_dir.joinpath('model/moses.ini')\n",
    "base_phrase_table = base_model_dir.joinpath('model/phrase-table.gz')\n",
    "base_reordering_table = base_model_dir.joinpath('model/reordering-table.wbe-msd-bidirectional-fe.gz')\n",
    "tuned_model_dir = model_dir.joinpath('tuned')\n",
    "tuned_moses_ini = tuned_model_dir.joinpath('moses.ini')\n",
    "binarised_model_dir = model_dir.joinpath('binarised')\n",
    "binarised_moses_ini = binarised_model_dir.joinpath('moses.ini')\n",
    "binarised_phrase_table = binarised_model_dir.joinpath('phrase-table')\n",
    "binarised_reordering_table = binarised_model_dir.joinpath('reordering-table')\n",
    "\n",
    "lm_out = binarised_model_dir.joinpath('lm.blm')\n",
    "\n",
    "\n",
    "prepare_binarisation(tuned_moses_ini, \n",
    "                     LM,\n",
    "                     lm_out, \n",
    "                     binarised_moses_ini, \n",
    "                     binarised_phrase_table, \n",
    "                     binarised_reordering_table)\n",
    "binarise_phrase_table(base_phrase_table, binarised_phrase_table)\n",
    "binarise_reordering_table(base_reordering_table, binarised_reordering_table)\n",
    "\n",
    "# translate\n",
    "translated = binarised_model_dir.joinpath(f'translated.{FROM}')\n",
    "\n",
    "translate_corpus(binarised_moses_ini, TEST_IN, translated)\n",
    "print(eval_translation(TEST_OUT, translated))\n",
    "print(*c.corpora_peek((TEST_OUT, translated)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/bin/bash: /work/is-en-kvistur/binarised/translated.is: No such file or directory']\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/work/is-en-kvistur/binarised/translated.is'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-e81c577801fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtranslated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinarised_model_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoinpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'translated.{FROM}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_translation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEST_OUT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranslated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpora_peek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEST_OUT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranslated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/project/corpus/corpus.py\u001b[0m in \u001b[0;36mcorpora_peek\u001b[0;34m(paths, length)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlangs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                 \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0;34mf'{lang.value}: {sentence}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/corpus/corpus.py\u001b[0m in \u001b[0;36mcorpus_peek\u001b[0;34m(path, length)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcorpus_peek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Returns the first length many lines from a given path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/jupyter/lib/python3.7/pathlib.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, mode, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m   1191\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         return io.open(self, mode, buffering, encoding, errors, newline,\n\u001b[0;32m-> 1193\u001b[0;31m                        opener=self._opener)\n\u001b[0m\u001b[1;32m   1194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/jupyter/lib/python3.7/pathlib.py\u001b[0m in \u001b[0;36m_opener\u001b[0;34m(self, name, flags, mode)\u001b[0m\n\u001b[1;32m   1044\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0o666\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m         \u001b[0;31m# A stub for the opener argument to built-in open()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_raw_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0o777\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/work/is-en-kvistur/binarised/translated.is'"
     ]
    }
   ],
   "source": [
    "TEST_OUT = en_test[FINAL]\n",
    "FROM = 'is'\n",
    "TO = 'en'\n",
    "MODIFIER = 'kvistur'\n",
    "model_dir = working_dir.joinpath(f'{FROM}-{TO}-{MODIFIER}')\n",
    "binarised_model_dir = model_dir.joinpath('binarised')\n",
    "translated = binarised_model_dir.joinpath(f'translated.{FROM}')\n",
    "print(eval_translation(TEST_OUT, translated))\n",
    "print(*c.corpora_peek((TEST_OUT, translated)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo\n",
    "Þýða einhvern texta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_en_is(moses_ini, sentence):\n",
    "    sentence = c.sent_process_v1(sentence, c.Lang.EN)\n",
    "    !echo \"{sentence}\" | {os.getenv('MOSESDECODER')}/bin/moses -f {moses_ini}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined parameters (per moses.ini or switch):\n",
      "\tconfig: /work/en-is-rmh-med/binarised/moses.ini \n",
      "\tdistortion-limit: 6 \n",
      "\tfeature: UnknownWordPenalty WordPenalty PhrasePenalty PhraseDictionaryCompact name=TranslationModel0 num-features=4 path=/work/en-is-rmh-med/binarised/phrase-table input-factor=0 output-factor=0 LexicalReordering name=LexicalReordering0 num-features=6 type=wbe-msd-bidirectional-fe-allff input-factor=0 output-factor=0 path=/work/en-is-rmh-med/binarised/reordering-table Distortion KENLM name=LM0 factor=0 path=/work/en-is-rmh-med/binarised/lm.blm order=4 \n",
      "\tinput-factors: 0 \n",
      "\tmapping: 0 T 0 \n",
      "\tthreads: 40 \n",
      "\tweight: LexicalReordering0= 0.224458 0.131272 0.141648 0.0173648 6.53242e-06 0.0673006 Distortion0= 0.00389063 LM0= 0.0500482 WordPenalty0= -0.153102 PhrasePenalty0= 0.00698338 TranslationModel0= 0.00295235 0.0162672 0.183913 -0.00079446 UnknownWordPenalty0= 1 \n",
      "line=UnknownWordPenalty\n",
      "FeatureFunction: UnknownWordPenalty0 start: 0 end: 0\n",
      "line=WordPenalty\n",
      "FeatureFunction: WordPenalty0 start: 1 end: 1\n",
      "line=PhrasePenalty\n",
      "FeatureFunction: PhrasePenalty0 start: 2 end: 2\n",
      "line=PhraseDictionaryCompact name=TranslationModel0 num-features=4 path=/work/en-is-rmh-med/binarised/phrase-table input-factor=0 output-factor=0\n",
      "FeatureFunction: TranslationModel0 start: 3 end: 6\n",
      "line=LexicalReordering name=LexicalReordering0 num-features=6 type=wbe-msd-bidirectional-fe-allff input-factor=0 output-factor=0 path=/work/en-is-rmh-med/binarised/reordering-table\n",
      "Initializing Lexical Reordering Feature..\n",
      "FeatureFunction: LexicalReordering0 start: 7 end: 12\n",
      "line=Distortion\n",
      "FeatureFunction: Distortion0 start: 13 end: 13\n",
      "line=KENLM name=LM0 factor=0 path=/work/en-is-rmh-med/binarised/lm.blm order=4\n",
      "FeatureFunction: LM0 start: 14 end: 14\n",
      "Loading UnknownWordPenalty0\n",
      "Loading WordPenalty0\n",
      "Loading PhrasePenalty0\n",
      "Loading LexicalReordering0\n",
      "Loading Distortion0\n",
      "Loading LM0\n",
      "Loading TranslationModel0\n",
      "Created input-output object : [4.642] seconds\n",
      "Translating: \n",
      "Line 1: Initialize search took 0.000 seconds total\n",
      "Line 1: Collecting options took 0.000 seconds at moses/Manager.cpp Line Translating: this 141\n",
      "is a proper english sentence , and we can have learnt a better phrase model \n",
      "Line 1: Search took 0.000 seconds\n",
      "Line 0: Initialize search took Line 1: Decision rule took 0.0010.000 seconds total\n",
      " seconds total\n",
      "Line 1: Additional reporting took 0.000 seconds total\n",
      "Line 1: Translation took 0.001 seconds total\n",
      "Line 0: Collecting options took 0.891 seconds at moses/Manager.cpp Line 141\n",
      "Line 0: Search took 0.181 seconds\n",
      "þetta er enskan setningunni og við getum hafa lært betri setning fyrirmynd \n",
      "BEST TRANSLATION: þetta er enskan setningunni og við getum hafa lært betri setning fyrirmynd [1111111111111111]  [total=-5.368] core=(0.000,-12.000,9.000,-16.231,-26.446,-5.542,-24.399,-1.818,0.000,0.000,-1.834,0.000,0.000,0.000,-106.908)  \n",
      "\n",
      "BEST TRANSLATION: []  [total=0.000] core=(0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000)  \n",
      "Line 0: Decision rule took 0.000 seconds total\n",
      "Line 0: Additional reporting took 0.000 seconds total\n",
      "Line 0: Translation took 1.073 seconds total\n",
      "Name:moses\tVmPeak:10271244 kB\tVmRSS:863296 kB\tRSSMax:9051528 kB\tuser:4.944\tsys:0.989\tCPU:5.932\treal:5.921\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "sentence = \"This is a proper English sentence, and we can have learnt a better phrase model\"\n",
    "print(translate_en_is(binarised_model_dir.joinpath('moses.ini'), sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_is_en(moses_ini, sentence):\n",
    "    sentence = c.sent_process_v1(sentence, c.Lang.IS)\n",
    "    !echo \"{sentence}\" | {os.getenv('MOSESDECODER')}/bin/moses -f {moses_ini}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined parameters (per moses.ini or switch):\n",
      "\tconfig: /work/is-en/binarised/moses.ini \n",
      "\tdistortion-limit: 6 \n",
      "\tfeature: UnknownWordPenalty WordPenalty PhrasePenalty PhraseDictionaryCompact name=TranslationModel0 num-features=4 path=/work/is-en/binarised/phrase-table input-factor=0 output-factor=0 LexicalReordering name=LexicalReordering0 num-features=6 type=wbe-msd-bidirectional-fe-allff input-factor=0 output-factor=0 path=/work/is-en/binarised/reordering-table Distortion KENLM name=LM0 factor=0 path=/work/is-en/binarised/lm-en.blm order=3 \n",
      "\tinput-factors: 0 \n",
      "\tmapping: 0 T 0 \n",
      "\tthreads: 14 \n",
      "\tweight: LexicalReordering0= 0.114192 0.0158818 0.0202684 0.083186 0.0208785 0.197803 Distortion0= 0.0160226 LM0= 0.0632488 WordPenalty0= -0.204654 PhrasePenalty0= -0.0417258 TranslationModel0= 0.0177732 0.00823355 0.188931 0.00720186 UnknownWordPenalty0= 1 \n",
      "line=UnknownWordPenalty\n",
      "FeatureFunction: UnknownWordPenalty0 start: 0 end: 0\n",
      "line=WordPenalty\n",
      "FeatureFunction: WordPenalty0 start: 1 end: 1\n",
      "line=PhrasePenalty\n",
      "FeatureFunction: PhrasePenalty0 start: 2 end: 2\n",
      "line=PhraseDictionaryCompact name=TranslationModel0 num-features=4 path=/work/is-en/binarised/phrase-table input-factor=0 output-factor=0\n",
      "FeatureFunction: TranslationModel0 start: 3 end: 6\n",
      "line=LexicalReordering name=LexicalReordering0 num-features=6 type=wbe-msd-bidirectional-fe-allff input-factor=0 output-factor=0 path=/work/is-en/binarised/reordering-table\n",
      "Initializing Lexical Reordering Feature..\n",
      "FeatureFunction: LexicalReordering0 start: 7 end: 12\n",
      "line=Distortion\n",
      "FeatureFunction: Distortion0 start: 13 end: 13\n",
      "line=KENLM name=LM0 factor=0 path=/work/is-en/binarised/lm-en.blm order=3\n",
      "FeatureFunction: LM0 start: 14 end: 14\n",
      "Loading UnknownWordPenalty0\n",
      "Loading WordPenalty0\n",
      "Loading PhrasePenalty0\n",
      "Loading LexicalReordering0\n",
      "Loading Distortion0\n",
      "Loading LM0\n",
      "Loading TranslationModel0\n",
      "Created input-output object : [1.002] seconds\n",
      "Translating: \n",
      "Line 1: Initialize search took Translating: 0.000 seconds total\n",
      "ég man ekkiLine 1: Collecting options took  eftir0.000 seconds at moses/Manager.cpp Line  neinum141\n",
      " góðum myndum nýlega \n",
      "Line 1: Search took 0.000 seconds\n",
      "Line 0: Initialize search took 0.001 seconds total\n",
      "Line 1: Decision rule took 0.000 seconds total\n",
      "Line 1: Additional reporting took 0.000 seconds total\n",
      "Line 1: Translation took 0.001 seconds total\n",
      "Line 0: Collecting options took 0.292 seconds at moses/Manager.cpp Line 141\n",
      "Line 0: Search took 0.059 seconds\n",
      "i can ' t even remember some good pictures recently \n",
      "BEST TRANSLATION: i can ' t even remember some good pictures recently [11111111]  [total=-2.430] core=(0.000,-10.000,3.000,-3.181,-21.657,-2.845,-23.124,-1.415,0.000,0.000,-1.022,0.000,0.000,0.000,-50.052)  \n",
      "\n",
      "BEST TRANSLATION: []  [total=0.000] core=(0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000)  \n",
      "Line 0: Decision rule took 0.000 seconds total\n",
      "Line 0: Additional reporting took 0.000 seconds total\n",
      "Line 0: Translation took 0.352 seconds total\n",
      "Name:moses\tVmPeak:2102776 kB\tVmRSS:486448 kB\tRSSMax:979400 kB\tuser:1.074\tsys:0.427\tCPU:1.502\treal:1.498\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Ég man ekki eftir neinum góðum myndum nýlega \"\n",
    "print(translate_is_en(working_dir.joinpath('is-en/binarised').joinpath('moses.ini'), sentence))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
