{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moses IS-EN EN-IS phrase þýðingarvél\n",
    "Sjá `README.md` til þess að keyra þetta vélrit (e. notebook).\n",
    "\n",
    "Í þessu vélriti eru gögn forunnin og Moses þýðingarkerfið notað til þess búa til tvö þýðingarkerfi, IS-EN og EN-IS.\n",
    "Það er gert ráð fyrir því að öll gögn séu aðgengileg undir `/work/data`. Sjá leiðbeiningar í `README.md` um hvernig það er gert með `docker` eða `singularity`.\n",
    "\n",
    "Í stuttu máli skiptist vélritið í eftirfarandi þætti:\n",
    "1. Samhliða og einhliða gögn undirbúin.\n",
    "1. Tungumála módel byggt fyrir EN og IS (KenLM).\n",
    "1. Texta skipt í þrjá hluta; train/val/test, fjöldi setninga í val/test er 3000/2000.\n",
    "1. Moses kerfið þjálfað með train hluta texta.\n",
    "1. Moses kerfið fínpússað með val hluta texta.\n",
    "1. Moses kerfið metið með BLEU mælingin á test hluta texta.\n",
    "\n",
    "Allar skrár og líkön eru raðað í skrána \"WORKING_DIR\" (sjá `README.md`).\n",
    "\n",
    "Safnið `corpus.py` skilgreinir föll og gagnategundir sem eru mikið nýttar hér."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/staff/haukurpj/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/staff/haukurpj/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict, Counter, OrderedDict\n",
    "import os\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import re\n",
    "from pprint import pprint\n",
    "import importlib\n",
    "from typing import List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import corpus.corpus as c\n",
    "\n",
    "importlib.reload(c)\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "working_dir = pathlib.Path('/work')\n",
    "data_dir = working_dir.joinpath('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's be sure that Moses is installed and the data is there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/moses\n",
      "/opt/moses_tools\n",
      "40\n",
      "bin  parice  risamalheild\r\n"
     ]
    }
   ],
   "source": [
    "print(os.getenv('MOSESDECODER'))\n",
    "print(os.getenv('MOSESDECODER_TOOLS'))\n",
    "print(int(os.getenv('THREADS')))\n",
    "!ls {data_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cat': PosixPath('/work/data/parice/cat.en'),\n",
      " 'sent_fix': PosixPath('/work/data/parice/sent_fix.en'),\n",
      " 'shuffle': PosixPath('/work/data/parice/shuffle.en')}\n",
      "{'cat': PosixPath('/work/data/parice/cat.is'),\n",
      " 'sent_fix': PosixPath('/work/data/parice/sent_fix.is'),\n",
      " 'shuffle': PosixPath('/work/data/parice/shuffle.is')}\n",
      "{'cat': PosixPath('/work/data/risamalheild/cat.is'),\n",
      " 'final': PosixPath('/work/data/risamalheild/final.is'),\n",
      " 'lm-blm': PosixPath('/work/data/risamalheild/lm-blm.is'),\n",
      " 'lower': PosixPath('/work/data/risamalheild/lower.is'),\n",
      " 'placeholders': None,\n",
      " 'regexp': PosixPath('/work/data/risamalheild/regexp.is'),\n",
      " 'sent_fix': PosixPath('/work/data/risamalheild/sent_fix.is'),\n",
      " 'tok': PosixPath('/work/data/risamalheild/tok.is')}\n",
      "{'drop': PosixPath('/work/data/parice/train/drop.en'),\n",
      " 'final': PosixPath('/work/data/parice/train/final.en'),\n",
      " 'length': PosixPath('/work/data/parice/train/length.en'),\n",
      " 'length-short': PosixPath('/work/data/parice/train/length-short.en'),\n",
      " 'lm-blm': PosixPath('/work/data/parice/train/lm-blm.en'),\n",
      " 'lower': PosixPath('/work/data/parice/train/lower.en'),\n",
      " 'placeholders': None,\n",
      " 'regexp': PosixPath('/work/data/parice/train/regexp.en'),\n",
      " 'shuffle': PosixPath('/work/data/parice/train/shuffle.en'),\n",
      " 'tok': PosixPath('/work/data/parice/train/tok.en'),\n",
      " 'translated_en_is': None,\n",
      " 'translated_is_en': None}\n",
      "{'drop': PosixPath('/work/data/parice/train/drop.is'),\n",
      " 'final': PosixPath('/work/data/parice/train/final.is'),\n",
      " 'length': PosixPath('/work/data/parice/train/length.is'),\n",
      " 'length-short': PosixPath('/work/data/parice/train/length-short.is'),\n",
      " 'lm-blm': PosixPath('/work/data/parice/train/lm-blm.is'),\n",
      " 'lower': PosixPath('/work/data/parice/train/lower.is'),\n",
      " 'placeholders': None,\n",
      " 'regexp': PosixPath('/work/data/parice/train/regexp.is'),\n",
      " 'shuffle': PosixPath('/work/data/parice/train/shuffle.is'),\n",
      " 'tok': PosixPath('/work/data/parice/train/tok.is'),\n",
      " 'translated_en_is': None,\n",
      " 'translated_is_en': None}\n"
     ]
    }
   ],
   "source": [
    "# List of stages in processing\n",
    "CAT = 'cat'\n",
    "SHUFFLE = 'shuffle'\n",
    "REGEXP = 'regexp'\n",
    "SENT_FIX = 'sent_fix'\n",
    "LOWER = 'lower'\n",
    "TOKENIZE = 'tok'\n",
    "PLACEHOLDERS = 'placeholders'\n",
    "LENGTH = 'length'\n",
    "LENGTH_SHORT = 'length-short'\n",
    "DROP = 'drop'\n",
    "LM = 'lm-blm'\n",
    "LM_3 = 'lm-blm-3'\n",
    "TRAIN = 'train'\n",
    "TEST = 'test'\n",
    "VAL = 'val'\n",
    "FINAL = 'final'\n",
    "TRANSLATED_EN_IS = 'translated_en_is'\n",
    "TRANSLATED_IS_EN = 'translated_is_en'\n",
    "\n",
    "parice_dir = data_dir.joinpath('parice')\n",
    "rmh_dir = data_dir.joinpath('risamalheild')\n",
    "train_parice_dir = parice_dir.joinpath('train')\n",
    "test_parice_dir = parice_dir.joinpath('test')\n",
    "val_parice_dir = parice_dir.joinpath('val')\n",
    "\n",
    "!mkdir -p {train_parice_dir}\n",
    "!mkdir -p {test_parice_dir}\n",
    "!mkdir -p {val_parice_dir}\n",
    "\n",
    "pipeline = [\n",
    "    SHUFFLE,\n",
    "    LOWER, \n",
    "    REGEXP, \n",
    "    TOKENIZE,\n",
    "    PLACEHOLDERS,\n",
    "    LENGTH,\n",
    "    LENGTH_SHORT,\n",
    "    LM,\n",
    "    FINAL,\n",
    "    DROP,\n",
    "    TRANSLATED_EN_IS,\n",
    "    TRANSLATED_IS_EN\n",
    "]\n",
    "rmh_stages = [\n",
    "    SENT_FIX,\n",
    "    LOWER,\n",
    "    REGEXP,\n",
    "    TOKENIZE,\n",
    "    PLACEHOLDERS,\n",
    "    LM,\n",
    "    FINAL,\n",
    "    CAT\n",
    "]\n",
    "parice_pipeline = [\n",
    "    CAT,\n",
    "    SENT_FIX,\n",
    "    SHUFFLE\n",
    "]\n",
    "\n",
    "# If we are not starting from scratch - we try to load all intermediary stages\n",
    "en_parice = c.pipeline_load(parice_dir, parice_pipeline, c.Lang.EN)\n",
    "is_parice = c.pipeline_load(parice_dir, parice_pipeline, c.Lang.IS)\n",
    "en_train = c.pipeline_load(train_parice_dir, pipeline, c.Lang.EN)\n",
    "is_train = c.pipeline_load(train_parice_dir, pipeline, c.Lang.IS)\n",
    "en_test = c.pipeline_load(test_parice_dir, pipeline, c.Lang.EN)\n",
    "is_test = c.pipeline_load(test_parice_dir, pipeline, c.Lang.IS)\n",
    "en_val = c.pipeline_load(val_parice_dir, pipeline, c.Lang.EN)\n",
    "is_val = c.pipeline_load(val_parice_dir, pipeline, c.Lang.IS)\n",
    "rmh = c.pipeline_load(rmh_dir, rmh_stages, c.Lang.IS)\n",
    "pprint(en_parice)\n",
    "pprint(is_parice)\n",
    "pprint(rmh)\n",
    "pprint(en_train)\n",
    "pprint(is_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stytta þjálfunarsetningar\n",
    "Moses á erfitt með að samstilla langar setningar. Við styttum þjálfunarsetningarnar svo einungis setningar sem eru eitt orð eða lengri upp að tölunni sem er skilgreint að neðan. Við höfum tekið eftir því að niðurstöðurnar sem við fáum með hámarkslengd (100) gefa ekki góðar niðurstöður.\n",
    "\n",
    "Þar sem við notum fall sem er skilgreint í Moses og tekur inn tvær skrár í einu fer nafnavenjan eitthvað á flakk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perl: warning: Setting locale failed.\n",
      "perl: warning: Please check that your locale settings:\n",
      "\tLANGUAGE = \"en_US:en\",\n",
      "\tLC_ALL = (unset),\n",
      "\tLC_CTYPE = \"C.UTF-8\",\n",
      "\tLANG = \"en_US.UTF-8\"\n",
      "    are supported and installed on your system.\n",
      "perl: warning: Falling back to the standard locale (\"C\").\n",
      "clean-corpus.perl: processing /work/data/parice/train/final.en & .is to /work/data/parice/train/length-short, cutoff 1-50, ratio 9\n",
      "..........(100000)..........(200000)..........(300000)..........(400000)..........(500000)..........(600000)..........(700000)..........(800000)..........(900000)..........(1000000)..........(1100000)..........(1200000)..........(1300000)..........(1400000)..........(1500000)..........(1600000)..........(1700000)..........(1800000)..........(1900000)..........(2000000)..........(2100000)..........(2200000)..........(2300000)..........(2400000)..........(2500000)..........(2600000)..........(2700000)..........(2800000)..........(2900000)..........(3000000)..........(3100000)..........(3200000)..........(3300000).......\n",
      "Input sentences: 3378149  Output sentences:  3246565\n"
     ]
    }
   ],
   "source": [
    "def corpus_shorten(path, path_out, lang_id_1, lang_id_2, min_length, max_length):\n",
    "    !{os.getenv('MOSESDECODER')}/scripts/training/clean-corpus-n.perl {path} {lang_id_1} {lang_id_2} {path_out} {min_length} {max_length}\n",
    "    return True\n",
    "\n",
    "path_out = is_train[FINAL].with_name(LENGTH_SHORT)\n",
    "path = is_train[FINAL].parent.joinpath(FINAL)\n",
    "corpus_shorten(path, path_out, 'en', 'is', 1, 50)\n",
    "\n",
    "is_train[LENGTH_SHORT] = is_train[FINAL].with_name(LENGTH_SHORT).with_suffix('.is')\n",
    "en_train[LENGTH_SHORT] = en_train[FINAL].with_name(LENGTH_SHORT).with_suffix('.en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tungumála módel\n",
    "Við búum til KenLM mállíkan til þess að gefa okkur líkindi setninga. Til að flýta uppflettingum þá tungumála módelið samtímis kjörsniðið."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lm(path, out_path, order):\n",
    "    tmp_arpa = c.corpus_create_path(path, 'arpa')\n",
    "    !{os.getenv('MOSESDECODER')}/bin/lmplz --order {order} --temp_prefix {data_dir}/ --memory 70% < {path} > {tmp_arpa}\n",
    "    !{os.getenv('MOSESDECODER')}/bin/build_binary -S 70% {tmp_arpa} {out_path}\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 1/5 Counting and sorting n-grams ===\n",
      "Reading /work/data/parice/train/final.is\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Unigram tokens 45111359 types 557672\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\n",
      "Chain sizes: 1:6692064 2:32821854208 3:61540978688\n",
      "Statistics:\n",
      "1 557672 D1=0.654933 D2=1.04977 D3+=1.39709\n",
      "2 5194483 D1=0.744091 D2=1.10969 D3+=1.42352\n",
      "3 13501935 D1=0.704238 D2=1.17861 D3+=1.46824\n",
      "Memory estimate for binary LM:\n",
      "type     MB\n",
      "probing 364 assuming -p 1.5\n",
      "probing 396 assuming -r models -p 1.5\n",
      "trie    161 without quantization\n",
      "trie     94 assuming -q 8 -b 8 quantization \n",
      "trie    151 assuming -a 22 array pointer compression\n",
      "trie     85 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\n",
      "Chain sizes: 1:6692064 2:83111728 3:270038700\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
      "Chain sizes: 1:6692064 2:83111728 3:270038700\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 5/5 Writing ARPA model ===\n",
      "Name:lmplz\tVmPeak:92317988 kB\tVmRSS:20912 kB\tRSSMax:21557996 kB\tuser:27.5237\tsys:11.9152\tCPU:39.4389\treal:62.6108\n",
      "Reading /work/data/parice/train/arpa.is\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "SUCCESS\n",
      "=== 1/5 Counting and sorting n-grams ===\n",
      "Reading /work/data/parice/train/final.en\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Unigram tokens 48291472 types 329669\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\n",
      "Chain sizes: 1:3956028 2:32822806528 3:61542760448\n",
      "Statistics:\n",
      "1 329669 D1=0.716064 D2=0.994607 D3+=1.26719\n",
      "2 3577181 D1=0.725363 D2=1.07465 D3+=1.36989\n",
      "3 11255547 D1=0.680109 D2=1.14927 D3+=1.44098\n",
      "Memory estimate for binary LM:\n",
      "type     MB\n",
      "probing 283 assuming -p 1.5\n",
      "probing 304 assuming -r models -p 1.5\n",
      "trie    119 without quantization\n",
      "trie     68 assuming -q 8 -b 8 quantization \n",
      "trie    113 assuming -a 22 array pointer compression\n",
      "trie     62 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\n",
      "Chain sizes: 1:3956028 2:57234896 3:225110940\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
      "Chain sizes: 1:3956028 2:57234896 3:225110940\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 5/5 Writing ARPA model ===\n",
      "Name:lmplz\tVmPeak:92317988 kB\tVmRSS:14284 kB\tRSSMax:21514404 kB\tuser:24.7046\tsys:11.3925\tCPU:36.0971\treal:49.6372\n",
      "Reading /work/data/parice/train/arpa.en\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "SUCCESS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_train[LM] = c.corpus_create_path(is_train[FINAL], LM)\n",
    "en_train[LM] = c.corpus_create_path(en_train[FINAL], LM)\n",
    "\n",
    "create_lm(is_train[FINAL], is_train[LM], order=3)\n",
    "create_lm(en_train[FINAL], en_train[LM], order=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sameina RMH og IS ParIce fyrir mállíkan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmh[CAT] = c.corpus_create_path(rmh[FINAL], CAT)\n",
    "c.corpora_combine((is_train[FINAL], rmh[FINAL]), rmh[CAT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Búa til mállíkan að lengd 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 1/5 Counting and sorting n-grams ===\n",
      "Reading /work/data/risamalheild/cat.is\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Unigram tokens 1459492635 types 5833046\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\n",
      "Chain sizes: 1:69996552 2:32799834112 3:61499691008\n",
      "Statistics:\n",
      "1 5833046 D1=0.702775 D2=1.03479 D3+=1.32363\n",
      "2 84061923 D1=0.746733 D2=1.07179 D3+=1.34939\n",
      "3 332835285 D1=0.69458 D2=1.29804 D3+=1.52235\n",
      "Memory estimate for binary LM:\n",
      "type      MB\n",
      "probing 7782 assuming -p 1.5\n",
      "probing 8285 assuming -r models -p 1.5\n",
      "trie    3428 without quantization\n",
      "trie    2044 assuming -q 8 -b 8 quantization \n",
      "trie    3227 assuming -a 22 array pointer compression\n",
      "trie    1844 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\n",
      "Chain sizes: 1:69996552 2:1344990768 3:6656705700\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
      "Chain sizes: 1:69996552 2:1344990768 3:6656705700\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 5/5 Writing ARPA model ===\n",
      "Name:lmplz\tVmPeak:92363312 kB\tVmRSS:6076 kB\tRSSMax:27882092 kB\tuser:849.246\tsys:105.078\tCPU:954.324\treal:1294.98\n",
      "Reading /work/data/risamalheild/arpa.is\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "SUCCESS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmh[LM_3] = c.corpus_create_path(rmh[CAT], LM)\n",
    "\n",
    "create_lm(rmh[CAT], rmh[LM_3], order=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prófa tungumála módel, það ættu ekki að vera nein óþekkt orð."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "þetta=408 2 -1.7515687\ter=108 3 -0.45247617\tflott=6918 4 -3.1981769\tíslensk=8107 2 -4.3185043\tsetning=37795 2 -5.0770183\t,=25 2 -1.4574796\ter=108 3 -2.1485984\tþað=260 3 -1.7368271\tekki=184 4 -0.7310319\t?=97 4 -0.9805836\t</s>=2 4 -0.06486414\tTotal: -21.917128 OOV: 0\n",
      "Perplexity including OOVs:\t98.28022595608707\n",
      "Perplexity excluding OOVs:\t98.28022595608707\n",
      "OOVs:\t0\n",
      "Tokens:\t11\n",
      "Name:query\tVmPeak:21003588 kB\tVmRSS:4812 kB\tRSSMax:20988044 kB\tuser:0.004002\tsys:1.60908\tCPU:1.61308\treal:1.67366\n",
      "this=195 2 -1.8074161\tis=188 3 -0.68361896\ta=12 3 -1.0045757\tnice=1048 3 -2.8550868\tenglish=6319 1 -4.6239047\tsentence=2958 1 -5.020405\t,=6 2 -1.1387969\tright=170 2 -3.7610703\t?=94 3 -0.14322345\t</s>=2 3 -0.034358077\tTotal: -21.072456 OOV: 0\n",
      "Perplexity including OOVs:\t128.0105124034037\n",
      "Perplexity excluding OOVs:\t128.0105124034037\n",
      "OOVs:\t0\n",
      "Tokens:\t10\n",
      "Name:query\tVmPeak:310420 kB\tVmRSS:4916 kB\tRSSMax:294980 kB\tuser:0\tsys:0.155038\tCPU:0.155038\treal:7.20459\n"
     ]
    }
   ],
   "source": [
    "def eval_sentence(lm_model, sentence):\n",
    "   !echo \"{sentence}\" | {os.getenv('MOSESDECODER')}/bin/query {lm_model}\n",
    "\n",
    "eval_sentence(rmh[LM], \"þetta er flott íslensk setning , er það ekki ?\")\n",
    "eval_sentence(en_train[LM], \"this is a nice english sentence , right ?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moses þjálfunar föll\n",
    "Næstu föll snúa að þjálfun Moses og annarra atriða sem þarf að hafa í huga. Þjálfunin tekur um 12 klst.\n",
    "Til þess að sjá framgang þjálfunar - sjá útprent þegar kallað er í föllin. Síðasta skrefið metur þýðingar Moses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_moses(model_dir, corpus, lang_from, lang_to, lang_to_lm, lm_order):\n",
    "    print(f'tail -f {model_dir}/training.out')\n",
    "    result = !{os.getenv('MOSESDECODER')}/scripts/training/train-model.perl -root-dir {model_dir} \\\n",
    "        -corpus {corpus} \\\n",
    "        -f {lang_from} -e {lang_to} \\\n",
    "        -alignment grow-diag-final-and -reordering msd-bidirectional-fe \\\n",
    "        -lm 0:{lm_order}:{lang_to_lm}:8 \\\n",
    "        -mgiza -mgiza-cpus {os.getenv('THREADS')} \\\n",
    "        -cores {os.getenv('THREADS')} \\\n",
    "        -external-bin-dir {os.getenv('MOSESDECODER_TOOLS')} &> {model_dir}/training.out\n",
    "    return model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_moses(model_dir, corpus_val_from, corpus_val_to, base_moses_ini):\n",
    "    print(f'tail -f {model_dir}/tune.out')\n",
    "    result = !{os.getenv('MOSESDECODER')}/scripts/training/mert-moses.pl \\\n",
    "        {corpus_val_from} \\\n",
    "        {corpus_val_to} \\\n",
    "        {os.getenv('MOSESDECODER')}/bin/moses {base_moses_ini} \\\n",
    "        --mertdir {os.getenv('MOSESDECODER')}/bin \\\n",
    "        --working-dir {model_dir} \\\n",
    "        --decoder-flags=\"-threads {os.getenv('THREADS')}\" &> {model_dir}/tune.out\n",
    "    return model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_binarisation(tuned_moses_ini,\n",
    "                         lm_path_in,\n",
    "                         lm_path_out,\n",
    "                         binarised_moses_ini,\n",
    "                         binarised_phrase_table,\n",
    "                         binarised_reordering_table):\n",
    "    !cp {tuned_moses_ini} {binarised_moses_ini}\n",
    "    !cp {lm_path_in} {lm_path_out}\n",
    "    # Adjust the path in the moses.ini file to point to the new files.\n",
    "    escaped_path_in = str(lm_path_in).replace(r'/', '\\/')\n",
    "    escaped_path_out = str(lm_path_out).replace(r'/', '\\/')\n",
    "    !sed -i 's/{escaped_path_in}/{escaped_path_out}/' {binarised_moses_ini}\n",
    "    # Adjust the path in the moses.ini file to point to the new files.\n",
    "    escaped_path = str(binarised_phrase_table).replace(r'/', '\\/')\n",
    "    !sed -i 's/PhraseDictionaryMemory/PhraseDictionaryCompact/' {binarised_moses_ini}\n",
    "    !sed -i 's/4 path=.*\\.gz input-factor/4 path={escaped_path} input-factor/' {binarised_moses_ini}\n",
    "    # Adjust the path in the moses.ini file\n",
    "    escaped_path = str(binarised_reordering_table).replace(r'/', '\\/')\n",
    "    !sed -i 's/0 path=.*\\.gz$/0 path={escaped_path}/' {binarised_moses_ini}\n",
    "    \n",
    "def binarise_phrase_table(base_phrase_table, binarised_phrase_table):\n",
    "    #Create the table\n",
    "    !{os.getenv('MOSESDECODER')}/bin/processPhraseTableMin \\\n",
    "        -in {base_phrase_table} \\\n",
    "        -nscores 4 \\\n",
    "        -out {binarised_phrase_table}\n",
    "    \n",
    "def binarise_reordering_table(base_reordering_table, binarised_reordering_table):\n",
    "    #Create the table\n",
    "    !{os.getenv('MOSESDECODER')}/bin/processLexicalTableMin \\\n",
    "        -in {base_reordering_table} \\\n",
    "        -out {binarised_reordering_table}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It only makes sense to filter the model when you know what text the system needs to translate.\n",
    "def filter_model(out_dir, moses_ini, corpus):\n",
    "    !{os.getenv('MOSESDECODER')}/scripts/training/filter-model-given-input.pl {out_dir} {moses_ini} {corpus}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_corpus(moses_ini, corpus, corpus_translated):\n",
    "    !{os.getenv('MOSESDECODER')}/bin/moses \\\n",
    "        -f {moses_ini} < {corpus} > {corpus_translated}\n",
    "    \n",
    "def eval_translation(corpus_gold, corpus_translated):\n",
    "    result = !{os.getenv('MOSESDECODER')}/scripts/generic/multi-bleu.perl -lc {corpus_gold} < {corpus_translated}\n",
    "    return result "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Byrja þjálfanir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tune_eval(LM,\n",
    "                    LM_ORDER,\n",
    "                    FROM,\n",
    "                    TO,\n",
    "                    MODIFIER,\n",
    "                    TRAIN_IN,\n",
    "                    VAL_IN,\n",
    "                    VAL_OUT,\n",
    "                    TEST_IN,\n",
    "                    TEST_OUT):\n",
    "    model_dir = working_dir.joinpath(f'{FROM}-{TO}-{MODIFIER}')\n",
    "    base_model_dir = model_dir.joinpath('base')\n",
    "    tuned_model_dir = model_dir.joinpath('tuned')\n",
    "    binarised_model_dir = model_dir.joinpath('binarised')\n",
    "    !mkdir -p {base_model_dir}\n",
    "    !mkdir -p {tuned_model_dir}\n",
    "    !mkdir -p {binarised_model_dir}\n",
    "\n",
    "    base_moses_ini = base_model_dir.joinpath('model/moses.ini')\n",
    "    base_phrase_table = base_model_dir.joinpath('model/phrase-table.gz')\n",
    "    base_reordering_table = base_model_dir.joinpath('model/reordering-table.wbe-msd-bidirectional-fe.gz')\n",
    "\n",
    "    tuned_moses_ini = tuned_model_dir.joinpath('moses.ini')\n",
    "\n",
    "    binarised_moses_ini = binarised_model_dir.joinpath('moses.ini')\n",
    "    binarised_phrase_table = binarised_model_dir.joinpath('phrase-table')\n",
    "    binarised_reordering_table = binarised_model_dir.joinpath('reordering-table')\n",
    "\n",
    "    # train\n",
    "    train_moses(base_model_dir, TRAIN_IN, FROM, TO, LM, lm_order=LM_ORDER)\n",
    "\n",
    "    # tune\n",
    "    tune_moses(tuned_model_dir, VAL_IN, VAL_OUT, base_moses_ini)\n",
    "\n",
    "    # binarise\n",
    "    !mkdir -p {binarised_model_dir}\n",
    "\n",
    "    lm_out = binarised_model_dir.joinpath('lm.blm')\n",
    "\n",
    "    prepare_binarisation(tuned_moses_ini, \n",
    "                         LM,\n",
    "                         lm_out, \n",
    "                         binarised_moses_ini, \n",
    "                         binarised_phrase_table, \n",
    "                         binarised_reordering_table)\n",
    "    binarise_phrase_table(base_phrase_table, binarised_phrase_table)\n",
    "    binarise_reordering_table(base_reordering_table, binarised_reordering_table)\n",
    "\n",
    "    # translate\n",
    "    translated = binarised_model_dir.joinpath(f'translated.{FROM}')\n",
    "\n",
    "    translate_corpus(binarised_moses_ini, TEST_IN, translated)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Með 50 orðum og minna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tail -f /work/en-is-rmh-med/base/training.out\n"
     ]
    }
   ],
   "source": [
    "train_tune_eval(LM = rmh[LM],\n",
    "                LM_ORDER = 4,\n",
    "                FROM = 'en',\n",
    "                TO = 'is',\n",
    "                MODIFIER = 'rmh-med',\n",
    "                TRAIN_IN = is_train[FINAL].parent.joinpath(LENGTH_SHORT),\n",
    "                VAL_IN = en_val[FINAL],\n",
    "                VAL_OUT = is_val[FINAL],\n",
    "                TEST_IN = en_test[FINAL],\n",
    "                TEST_OUT = is_test[FINAL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tune_eval(LM = en_train[LM],\n",
    "                LM_ORDER = 3,\n",
    "                FROM = 'is',\n",
    "                TO = 'en',\n",
    "                MODIFIER = 'rmh-med',\n",
    "                TRAIN_IN = is_train[FINAL].parent.joinpath(LENGTH_SHORT),\n",
    "                VAL_IN = is_val[FINAL],\n",
    "                VAL_OUT = en_val[FINAL],\n",
    "                TEST_IN = is_test[FINAL],\n",
    "                TEST_OUT = en_test[FINAL])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sama nema líka með LM order 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tune_eval(LM = rmh[LM_3],\n",
    "                LM_ORDER = 3,\n",
    "                FROM = 'en',\n",
    "                TO = 'is',\n",
    "                MODIFIER = 'rmh-3-med',\n",
    "                TRAIN_IN = is_train[FINAL].parent.joinpath(LENGTH_SHORT),\n",
    "                VAL_IN = en_val[FINAL],\n",
    "                VAL_OUT = is_val[FINAL],\n",
    "                TEST_IN = en_test[FINAL],\n",
    "                TEST_OUT = is_test[FINAL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['perl: warning: Setting locale failed.', 'perl: warning: Please check that your locale settings:', '\\tLANGUAGE = \"en_US:en\",', '\\tLC_ALL = (unset),', '\\tLC_CTYPE = \"C.UTF-8\",', '\\tLANG = \"en_US.UTF-8\"', '    are supported and installed on your system.', 'perl: warning: Falling back to the standard locale (\"C\").', 'It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.', 'BLEU = 53.45, 74.8/57.2/47.6/40.8 (BP=0.996, ratio=0.996, hyp_len=40345, ref_len=40526)']\n",
      "en: • 6 km for category 2 motorcycle ( engine capacity ≥ 150 cc , vmax @lt@ 130 km/h ) ,\n",
      " is: • 6 km for category 2 motorcycle ( engine capacity ≥ 150 cc , vmax @lt@ 130 km/h ) , \n",
      " en: e. common learning article 5( 1 ) ( e )\n",
      " is: e. common learning article 5( 1 ) ( e ) . \n",
      " en: measurement of exhaust gas opacity with free acceleration ( no load from idling up to cut-off speed ) .\n",
      " is: measurement of exhaust gas opacity with free acceleration ( no load from idle up to cut-off speed , in a no-load state ) . \n",
      " en: other trailers and semi-trailers\n",
      " is: other trailers and semi-trailers \n",
      " en: i have food poisoning .\n",
      " is: i ' ve got food poisoning . \n",
      " en: pearls as big as coconuts .\n",
      " is: pearls the size of coconuts . \n",
      " en: this objective shall be measured , in particular , through the increase in the number of member states integrating coherent approaches in the design of their preparedness plans .\n",
      " is: this objective shall be measured , in particular , through the increase in the number of member states include coherent approaches in the preparation of the contingency plans . \n",
      " en: everybody off. we ' ve got a problem .\n",
      " is: everybody out , we ' re in trouble . \n",
      " en: steady-state level of sonidegib in the skin was 6-fold higher than in plasma .\n",
      " is: at steady state , the concentration of sonidegib of the skin 6-fold higher than in plasma . \n",
      " en: the time to onset of symptoms varied from one day to several months after starting treatment .\n",
      " is: symptoms was observed as early from one day to several months after the initiation of treatment . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "TEST_OUT = en_test[FINAL]\n",
    "FROM = 'is'\n",
    "TO = 'en'\n",
    "MODIFIER = 'short'\n",
    "model_dir = working_dir.joinpath(f'{FROM}-{TO}')\n",
    "binarised_model_dir = model_dir.joinpath('binarised')\n",
    "translated = binarised_model_dir.joinpath(f'translated.{FROM}')\n",
    "print(eval_translation(TEST_OUT, translated))\n",
    "print(*c.corpora_peek((TEST_OUT, translated)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo\n",
    "Þýða einhvern texta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_en_is(moses_ini, sentence):\n",
    "    sentence = c.sent_process_v1(sentence, c.Lang.EN)\n",
    "    !echo \"{sentence}\" | {os.getenv('MOSESDECODER')}/bin/moses -f {moses_ini}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined parameters (per moses.ini or switch):\n",
      "\tconfig: /work/en-is-rmh/binarised/moses.ini \n",
      "\tdistortion-limit: 6 \n",
      "\tfeature: UnknownWordPenalty WordPenalty PhrasePenalty PhraseDictionaryCompact name=TranslationModel0 num-features=4 path=/work/en-is-rmh/binarised/phrase-table input-factor=0 output-factor=0 LexicalReordering name=LexicalReordering0 num-features=6 type=wbe-msd-bidirectional-fe-allff input-factor=0 output-factor=0 path=/work/en-is-rmh/binarised/reordering-table Distortion KENLM name=LM0 factor=0 path=/work/en-is-rmh/binarised/lm.blm order=4 \n",
      "\tinput-factors: 0 \n",
      "\tmapping: 0 T 0 \n",
      "\tthreads: 40 \n",
      "\tweight: LexicalReordering0= 0.0384378 0.0859153 0.0405209 0.0884273 0.0272562 0.101296 Distortion0= 0.0313493 LM0= 0.0992259 WordPenalty0= -0.165075 PhrasePenalty0= 0.0804042 TranslationModel0= 0.0395704 0.0341685 0.165878 0.00247474 UnknownWordPenalty0= 1 \n",
      "line=UnknownWordPenalty\n",
      "FeatureFunction: UnknownWordPenalty0 start: 0 end: 0\n",
      "line=WordPenalty\n",
      "FeatureFunction: WordPenalty0 start: 1 end: 1\n",
      "line=PhrasePenalty\n",
      "FeatureFunction: PhrasePenalty0 start: 2 end: 2\n",
      "line=PhraseDictionaryCompact name=TranslationModel0 num-features=4 path=/work/en-is-rmh/binarised/phrase-table input-factor=0 output-factor=0\n",
      "FeatureFunction: TranslationModel0 start: 3 end: 6\n",
      "line=LexicalReordering name=LexicalReordering0 num-features=6 type=wbe-msd-bidirectional-fe-allff input-factor=0 output-factor=0 path=/work/en-is-rmh/binarised/reordering-table\n",
      "Initializing Lexical Reordering Feature..\n",
      "FeatureFunction: LexicalReordering0 start: 7 end: 12\n",
      "line=Distortion\n",
      "FeatureFunction: Distortion0 start: 13 end: 13\n",
      "line=KENLM name=LM0 factor=0 path=/work/en-is-rmh/binarised/lm.blm order=4\n",
      "FeatureFunction: LM0 start: 14 end: 14\n",
      "Loading UnknownWordPenalty0\n",
      "Loading WordPenalty0\n",
      "Loading PhrasePenalty0\n",
      "Loading LexicalReordering0\n",
      "Loading Distortion0\n",
      "Loading LM0\n",
      "Loading TranslationModel0\n",
      "Created input-output object : [6.321] seconds\n",
      "Translating: \n",
      "Line 1: Initialize search took 0.000 seconds total\n",
      "Line 1: Collecting options took 0.000 seconds at moses/Manager.cpp Line 141\n",
      "Line 1: Search took 0.000 seconds\n",
      "Line 1: Decision rule took 0.000 seconds total\n",
      "Line 1: Additional reporting took 0.000 seconds total\n",
      "Line 1: Translation took 0.001Translating: this is a proper english sentence ,  seconds total\n",
      "and we can have learnt a better phrase model \n",
      "Line 0: Initialize search took 0.001 seconds total\n",
      "Line 0: Collecting options took 6.794 seconds at moses/Manager.cpp Line 141\n",
      "Line 0: Search took 0.292 seconds\n",
      "þetta er enskan setningunni og við getum lært betri fyrirmynd . \n",
      "BEST TRANSLATION: þetta er enskan setningunni og við getum lært betri fyrirmynd . [1111111111111111]  [total=-10.499] core=(0.000,-11.000,8.000,-33.912,-42.396,-10.696,-26.002,-2.814,-1.946,-1.920,-2.665,-3.000,-2.342,-3.000,-73.841)  \n",
      "\n",
      "BEST TRANSLATION: []  [total=0.000] core=(0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000)  \n",
      "Line 0: Decision rule took 0.000 seconds total\n",
      "Line 0: Additional reporting took 0.000 seconds total\n",
      "Line 0: Translation took 7.087 seconds total\n",
      "Name:moses\tVmPeak:23444796 kB\tVmRSS:945960 kB\tRSSMax:22142732 kB\tuser:6.639\tsys:2.095\tCPU:8.734\treal:14.004\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "sentence = \"This is a proper English sentence, and we can have learnt a better phrase model\"\n",
    "print(translate_en_is(binarised_model_dir.joinpath('moses.ini'), sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_is_en(moses_ini, sentence):\n",
    "    sentence = c.sent_process_v1(sentence, c.Lang.IS)\n",
    "    !echo \"{sentence}\" | {os.getenv('MOSESDECODER')}/bin/moses -f {moses_ini}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined parameters (per moses.ini or switch):\n",
      "\tconfig: /work/is-en/binarised/moses.ini \n",
      "\tdistortion-limit: 6 \n",
      "\tfeature: UnknownWordPenalty WordPenalty PhrasePenalty PhraseDictionaryCompact name=TranslationModel0 num-features=4 path=/work/is-en/binarised/phrase-table input-factor=0 output-factor=0 LexicalReordering name=LexicalReordering0 num-features=6 type=wbe-msd-bidirectional-fe-allff input-factor=0 output-factor=0 path=/work/is-en/binarised/reordering-table Distortion KENLM name=LM0 factor=0 path=/work/is-en/binarised/lm-en.blm order=3 \n",
      "\tinput-factors: 0 \n",
      "\tmapping: 0 T 0 \n",
      "\tthreads: 14 \n",
      "\tweight: LexicalReordering0= 0.114192 0.0158818 0.0202684 0.083186 0.0208785 0.197803 Distortion0= 0.0160226 LM0= 0.0632488 WordPenalty0= -0.204654 PhrasePenalty0= -0.0417258 TranslationModel0= 0.0177732 0.00823355 0.188931 0.00720186 UnknownWordPenalty0= 1 \n",
      "line=UnknownWordPenalty\n",
      "FeatureFunction: UnknownWordPenalty0 start: 0 end: 0\n",
      "line=WordPenalty\n",
      "FeatureFunction: WordPenalty0 start: 1 end: 1\n",
      "line=PhrasePenalty\n",
      "FeatureFunction: PhrasePenalty0 start: 2 end: 2\n",
      "line=PhraseDictionaryCompact name=TranslationModel0 num-features=4 path=/work/is-en/binarised/phrase-table input-factor=0 output-factor=0\n",
      "FeatureFunction: TranslationModel0 start: 3 end: 6\n",
      "line=LexicalReordering name=LexicalReordering0 num-features=6 type=wbe-msd-bidirectional-fe-allff input-factor=0 output-factor=0 path=/work/is-en/binarised/reordering-table\n",
      "Initializing Lexical Reordering Feature..\n",
      "FeatureFunction: LexicalReordering0 start: 7 end: 12\n",
      "line=Distortion\n",
      "FeatureFunction: Distortion0 start: 13 end: 13\n",
      "line=KENLM name=LM0 factor=0 path=/work/is-en/binarised/lm-en.blm order=3\n",
      "FeatureFunction: LM0 start: 14 end: 14\n",
      "Loading UnknownWordPenalty0\n",
      "Loading WordPenalty0\n",
      "Loading PhrasePenalty0\n",
      "Loading LexicalReordering0\n",
      "Loading Distortion0\n",
      "Loading LM0\n",
      "Loading TranslationModel0\n",
      "Created input-output object : [1.002] seconds\n",
      "Translating: \n",
      "Line 1: Initialize search took Translating: 0.000 seconds total\n",
      "ég man ekkiLine 1: Collecting options took  eftir0.000 seconds at moses/Manager.cpp Line  neinum141\n",
      " góðum myndum nýlega \n",
      "Line 1: Search took 0.000 seconds\n",
      "Line 0: Initialize search took 0.001 seconds total\n",
      "Line 1: Decision rule took 0.000 seconds total\n",
      "Line 1: Additional reporting took 0.000 seconds total\n",
      "Line 1: Translation took 0.001 seconds total\n",
      "Line 0: Collecting options took 0.292 seconds at moses/Manager.cpp Line 141\n",
      "Line 0: Search took 0.059 seconds\n",
      "i can ' t even remember some good pictures recently \n",
      "BEST TRANSLATION: i can ' t even remember some good pictures recently [11111111]  [total=-2.430] core=(0.000,-10.000,3.000,-3.181,-21.657,-2.845,-23.124,-1.415,0.000,0.000,-1.022,0.000,0.000,0.000,-50.052)  \n",
      "\n",
      "BEST TRANSLATION: []  [total=0.000] core=(0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000)  \n",
      "Line 0: Decision rule took 0.000 seconds total\n",
      "Line 0: Additional reporting took 0.000 seconds total\n",
      "Line 0: Translation took 0.352 seconds total\n",
      "Name:moses\tVmPeak:2102776 kB\tVmRSS:486448 kB\tRSSMax:979400 kB\tuser:1.074\tsys:0.427\tCPU:1.502\treal:1.498\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Ég man ekki eftir neinum góðum myndum nýlega \"\n",
    "print(translate_is_en(working_dir.joinpath('is-en/binarised').joinpath('moses.ini'), sentence))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
