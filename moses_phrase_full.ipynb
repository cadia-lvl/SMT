{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moses IS-EN EN-IS phrase þýðingarvél\n",
    "Sjá `README.md` til þess að keyra þetta vélrit (e. notebook).\n",
    "\n",
    "Í þessu vélriti eru gögn forunnin og Moses þýðingarkerfið notað til þess búa til tvö þýðingarkerfi, IS-EN og EN-IS.\n",
    "Það er gert ráð fyrir því að öll gögn séu aðgengileg undir `/work/data`. Sjá leiðbeiningar í `README.md` um hvernig það er gert með `docker` eða `singularity`.\n",
    "\n",
    "Í stuttu máli skiptist vélritið í eftirfarandi þætti:\n",
    "1. Samhliða og einhliða gögn undirbúin.\n",
    "1. Tungumála módel byggt fyrir EN og IS (KenLM).\n",
    "1. Texta skipt í þrjá hluta; train/val/test, fjöldi setninga í val/test er 3000/2000.\n",
    "1. Moses kerfið þjálfað með train hluta texta.\n",
    "1. Moses kerfið fínpússað með val hluta texta.\n",
    "1. Moses kerfið metið með BLEU mælingin á test hluta texta.\n",
    "\n",
    "Allar skrár og líkön eru raðað í skrána \"WORKING_DIR\" (sjá `README.md`).\n",
    "\n",
    "Safnið `corpus.py` skilgreinir föll og gagnategundir sem eru mikið nýttar hér."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/moses\n",
      "/opt/moses_tools\n",
      "15\n",
      "32768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/staff/haukurpj/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict, Counter, OrderedDict\n",
    "import os\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import re\n",
    "from pprint import pprint\n",
    "import importlib\n",
    "from typing import List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import corpus.corpus as c\n",
    "\n",
    "importlib.reload(c)\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "print(os.getenv('MOSESDECODER'))\n",
    "print(os.getenv('MOSESDECODER_TOOLS'))\n",
    "print(int(os.getenv('THREADS')))\n",
    "print(int(os.getenv('MEMORY')))\n",
    "\n",
    "working_dir = pathlib.Path('/work')\n",
    "data_dir = working_dir.joinpath('data')\n",
    "processing_dir = working_dir.joinpath('process')\n",
    "p = processing_dir\n",
    "parice_dir = data_dir.joinpath('parice')\n",
    "rmh_dir = data_dir.joinpath('risamalheild')\n",
    "\n",
    "IS = c.Lang.IS\n",
    "EN = c.Lang.EN\n",
    "\n",
    "RMH, PARICE = 'rmh', 'parice'\n",
    "TRAIN, VAL, TEST = 'train', 'val', 'test'\n",
    "\n",
    "langs = [IS, EN]\n",
    "splits = [TRAIN, VAL, TEST]\n",
    "\n",
    "CAT = 'cat'\n",
    "SHUFFLE = 'shuffle'\n",
    "REGEXP = 'regexp'\n",
    "SENT_FIX = 'sent_fix'\n",
    "LOWER = 'lower'\n",
    "TOKENIZE = 'tok'\n",
    "PLACEHOLDERS = 'placeholders'\n",
    "LENGTH = 'length'\n",
    "DROP = 'drop'\n",
    "LM = 'lm-blm'\n",
    "KVISTUR = 'kvistur'\n",
    "BPE = 'bpe'\n",
    "TRAIN = 'train'\n",
    "TEST = 'test'\n",
    "VAL = 'val'\n",
    "FINAL = 'final'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stytta þjálfunarsetningar\n",
    "Moses á erfitt með að samstilla langar setningar. Við styttum þjálfunarsetningarnar svo einungis setningar sem eru eitt orð eða lengri upp að tölunni sem er skilgreint að neðan. Við höfum tekið eftir því að niðurstöðurnar sem við fáum með hámarkslengd (100) gefa ekki góðar niðurstöður.\n",
    "\n",
    "Þar sem við notum fall sem er skilgreint í Moses og tekur inn tvær skrár í einu fer nafnavenjan eitthvað á flakk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perl: warning: Setting locale failed.\n",
      "perl: warning: Please check that your locale settings:\n",
      "\tLANGUAGE = \"en_US:en\",\n",
      "\tLC_ALL = (unset),\n",
      "\tLC_CTYPE = \"C.UTF-8\",\n",
      "\tLANG = \"en_US.UTF-8\"\n",
      "    are supported and installed on your system.\n",
      "perl: warning: Falling back to the standard locale (\"C\").\n",
      "clean-corpus.perl: processing /work/process/parice-train-final.en & .is to /work/process/parice-train-length, cutoff 1-70, ratio 9\n",
      "..........(100000)..........(200000)..........(300000)..........(400000)..........(500000)..........(600000)..........(700000)..........(800000)..........(900000)..........(1000000)..........(1100000)..........(1200000)..........(1300000)..........(1400000)..........(1500000)..........(1600000)..........(1700000)..........(1800000)..........(1900000)..........(2000000)..........(2100000)..........(2200000)..........(2300000)..........(2400000)..........(2500000)..........(2600000)..........(2700000)..........(2800000)..........(2900000)..........(3000000)..........(3100000)..........(3200000)..........(3300000).....\n",
      "Input sentences: 3351141  Output sentences:  3311201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def corpus_shorten(path, path_out, lang_id_1, lang_id_2, min_length, max_length):\n",
    "    !{os.getenv('MOSESDECODER')}/scripts/training/clean-corpus-n.perl {path} {lang_id_1} {lang_id_2} {path_out} {min_length} {max_length}\n",
    "    return True\n",
    "\n",
    "# IS is ignored\n",
    "IN = c.read(p, IS, PARICE, TRAIN, FINAL).with_suffix('')\n",
    "OUT = c.write(p, IS, PARICE, TRAIN, LENGTH).with_suffix('')\n",
    "\n",
    "corpus_shorten(IN, OUT, 'en', 'is', 1, 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tungumála módel\n",
    "Við búum til KenLM mállíkan til þess að gefa okkur líkindi setninga. Til að flýta uppflettingum þá tungumála módelið samtímis kjörsniðið."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lm(path, out_path, order):\n",
    "    tmp_arpa = out_path.with_suffix('.arpa')\n",
    "    !{os.getenv('MOSESDECODER')}/bin/lmplz --order {order} --temp_prefix {data_dir}/ --memory 50% --discount_fallback < {path} > {tmp_arpa}\n",
    "    !{os.getenv('MOSESDECODER')}/bin/build_binary -S 50% {tmp_arpa} {out_path}\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EN mállíkan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 1/5 Counting and sorting n-grams ===\n",
      "Reading /work/process/parice-train-length.en\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Unigram tokens 45972494 types 252581\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\n",
      "Chain sizes: 1:3030972 2:23444791296 3:43958984704\n",
      "Statistics:\n",
      "1 252581 D1=0.662731 D2=1.03135 D3+=1.3416\n",
      "2 3344252 D1=0.712012 D2=1.08004 D3+=1.39646\n",
      "3 10877598 D1=0.680056 D2=1.14824 D3+=1.4491\n",
      "Memory estimate for binary LM:\n",
      "type     MB\n",
      "probing 269 assuming -p 1.5\n",
      "probing 289 assuming -r models -p 1.5\n",
      "trie    111 without quantization\n",
      "trie     62 assuming -q 8 -b 8 quantization \n",
      "trie    105 assuming -a 22 array pointer compression\n",
      "trie     56 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\n",
      "Chain sizes: 1:3030972 2:53508032 3:217551960\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
      "Chain sizes: 1:3030972 2:53508032 3:217551960\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 5/5 Writing ARPA model ===\n",
      "Name:lmplz\tVmPeak:65987200 kB\tVmRSS:13160 kB\tRSSMax:15428792 kB\tuser:23.3536\tsys:8.80375\tCPU:32.1573\treal:30.1555\n",
      "Reading /work/process/parice-train-lm-blm.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "SUCCESS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_lm(c.read(p, EN, PARICE, TRAIN, LENGTH), c.write(p, EN, PARICE, TRAIN, LM), order=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IS mállíkan (RMH + TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.combine((c.read(p, IS, PARICE, TRAIN, FINAL), \n",
    "           c.read(p, IS, RMH, FINAL)), \n",
    "          c.write(p, IS, RMH, TRAIN, CAT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 1/5 Counting and sorting n-grams ===\n",
      "Reading /work/process/rmh-train-cat.is\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "************"
     ]
    }
   ],
   "source": [
    "create_lm(c.read(p, IS, RMH, TRAIN, CAT), c.write(p, IS, RMH, TRAIN, CAT, LM), order=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prófa tungumála módel, það ættu ekki að vera nein óþekkt orð."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "þetta=416 2 -1.7512153\ter=105 3 -0.45226997\tflott=7093 3 -3.175889\tíslensk=8308 2 -4.092872\tsetning=39567 2 -5.111964\t,=25 2 -1.514426\ter=105 3 -2.4005053\tþað=264 3 -1.3744158\tekki=189 3 -1.170756\t?=94 3 -1.5291206\t</s>=2 3 -0.05531629\tTotal: -22.628752 OOV: 0\n",
      "Perplexity including OOVs:\t114.06679797702375\n",
      "Perplexity excluding OOVs:\t114.06679797702375\n",
      "OOVs:\t0\n",
      "Tokens:\t11\n",
      "Name:query\tVmPeak:8210512 kB\tVmRSS:4860 kB\tRSSMax:8195016 kB\tuser:0\tsys:8.79275\tCPU:8.79275\treal:8.78055\n",
      "this=208 2 -1.798729\tis=200 3 -0.6794696\ta=12 3 -1.0007749\tnice=994 3 -2.8335419\tenglish=6077 1 -4.5991697\tsentence=2824 1 -5.0001507\t,=6 2 -1.1415414\tright=182 2 -3.7487242\t?=93 3 -0.14266676\t</s>=2 3 -0.034414142\tTotal: -20.979181 OOV: 0\n",
      "Perplexity including OOVs:\t125.2904961274026\n",
      "Perplexity excluding OOVs:\t125.2904961274026\n",
      "OOVs:\t0\n",
      "Tokens:\t10\n",
      "Name:query\tVmPeak:296704 kB\tVmRSS:5000 kB\tRSSMax:281348 kB\tuser:0\tsys:0.428492\tCPU:0.428492\treal:0.431875\n"
     ]
    }
   ],
   "source": [
    "def eval_sentence(lm_model, sentence):\n",
    "   !echo \"{sentence}\" | {os.getenv('MOSESDECODER')}/bin/query {lm_model}\n",
    "\n",
    "eval_sentence(c.read(p, IS, RMH, TRAIN, CAT, LM, 'moses'), \"þetta er flott íslensk setning , er það ekki ?\")\n",
    "eval_sentence(c.read(p, EN, PARICE, TRAIN, LM, 'moses'), \"this is a nice english sentence , right ?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moses þjálfunar föll\n",
    "Næstu föll snúa að þjálfun Moses og annarra atriða sem þarf að hafa í huga. Þjálfunin tekur um 12 klst.\n",
    "Til þess að sjá framgang þjálfunar - sjá útprent þegar kallað er í föllin. Síðasta skrefið metur þýðingar Moses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_moses(model_dir, corpus, lang_from, lang_to, lang_to_lm, lm_order):\n",
    "    print(f'tail -f {model_dir}/training.out')\n",
    "    result = !{os.getenv('MOSESDECODER')}/scripts/training/train-model.perl -root-dir {model_dir} \\\n",
    "        -corpus {corpus} \\\n",
    "        -f {lang_from} -e {lang_to} \\\n",
    "        -alignment grow-diag-final-and -reordering msd-bidirectional-fe \\\n",
    "        -lm 0:{lm_order}:{lang_to_lm}:8 \\\n",
    "        -mgiza -mgiza-cpus {os.getenv('THREADS')} \\\n",
    "        -parallel -sort-buffer-size {os.getenv('MEMORY')} -sort-batch-size 1021 \\\n",
    "        -sort-compress gzip -sort-parallel {os.getenv('THREADS')} \\\n",
    "        -cores {os.getenv('THREADS')} \\\n",
    "        -external-bin-dir {os.getenv('MOSESDECODER_TOOLS')} &> {model_dir}/training.out\n",
    "    return model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_moses(model_dir, corpus_val_from, corpus_val_to, base_moses_ini):\n",
    "    print(f'tail -f {model_dir}/tune.out')\n",
    "    result = !{os.getenv('MOSESDECODER')}/scripts/training/mert-moses.pl \\\n",
    "        {corpus_val_from} \\\n",
    "        {corpus_val_to} \\\n",
    "        {os.getenv('MOSESDECODER')}/bin/moses {base_moses_ini} \\\n",
    "        --mertdir {os.getenv('MOSESDECODER')}/bin \\\n",
    "        --working-dir {model_dir} \\\n",
    "        --decoder-flags=\"-threads {os.getenv('THREADS')}\" &> {model_dir}/tune.out\n",
    "    return model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_binarisation(tuned_moses_ini,\n",
    "                         lm_path_in,\n",
    "                         lm_path_out,\n",
    "                         binarised_moses_ini,\n",
    "                         binarised_phrase_table,\n",
    "                         binarised_reordering_table):\n",
    "    !cp {tuned_moses_ini} {binarised_moses_ini}\n",
    "    !cp {lm_path_in} {lm_path_out}\n",
    "    # Adjust the path in the moses.ini file to point to the new files.\n",
    "    escaped_path_in = str(lm_path_in).replace(r'/', '\\/')\n",
    "    escaped_path_out = str(lm_path_out).replace(r'/', '\\/')\n",
    "    !sed -i 's/{escaped_path_in}/{escaped_path_out}/' {binarised_moses_ini}\n",
    "    # Adjust the path in the moses.ini file to point to the new files.\n",
    "    escaped_path = str(binarised_phrase_table).replace(r'/', '\\/')\n",
    "    !sed -i 's/PhraseDictionaryMemory/PhraseDictionaryCompact/' {binarised_moses_ini}\n",
    "    !sed -i 's/4 path=.*\\.gz input-factor/4 path={escaped_path} input-factor/' {binarised_moses_ini}\n",
    "    # Adjust the path in the moses.ini file\n",
    "    escaped_path = str(binarised_reordering_table).replace(r'/', '\\/')\n",
    "    !sed -i 's/0 path=.*\\.gz$/0 path={escaped_path}/' {binarised_moses_ini}\n",
    "    \n",
    "def binarise_phrase_table(base_phrase_table, binarised_phrase_table):\n",
    "    #Create the table\n",
    "    !{os.getenv('MOSESDECODER')}/bin/processPhraseTableMin \\\n",
    "        -in {base_phrase_table} \\\n",
    "        -nscores 4 \\\n",
    "        -out {binarised_phrase_table}\n",
    "    \n",
    "def binarise_reordering_table(base_reordering_table, binarised_reordering_table):\n",
    "    #Create the table\n",
    "    !{os.getenv('MOSESDECODER')}/bin/processLexicalTableMin \\\n",
    "        -in {base_reordering_table} \\\n",
    "        -out {binarised_reordering_table}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It only makes sense to filter the model when you know what text the system needs to translate.\n",
    "def filter_model(out_dir, moses_ini, corpus):\n",
    "    !{os.getenv('MOSESDECODER')}/scripts/training/filter-model-given-input.pl {out_dir} {moses_ini} {corpus}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_corpus(moses_ini, corpus, corpus_translated):\n",
    "    !{os.getenv('MOSESDECODER')}/bin/moses \\\n",
    "        -f {moses_ini} < {corpus} > {corpus_translated}\n",
    "    \n",
    "def eval_translation(corpus_gold, corpus_translated):\n",
    "    result = !{os.getenv('MOSESDECODER')}/scripts/generic/multi-bleu.perl -lc {corpus_gold} < {corpus_translated}\n",
    "    return result "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Byrja þjálfanir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tune_eval(LM,\n",
    "                    LM_ORDER,\n",
    "                    FROM,\n",
    "                    TO,\n",
    "                    MODIFIER,\n",
    "                    TRAIN_IN,\n",
    "                    VAL_IN,\n",
    "                    VAL_OUT,\n",
    "                    TEST_IN,\n",
    "                    TEST_OUT):\n",
    "    model_dir = working_dir.joinpath(f'{FROM}-{TO}-{MODIFIER}')\n",
    "    base_model_dir = model_dir.joinpath('base')\n",
    "    tuned_model_dir = model_dir.joinpath('tuned')\n",
    "    binarised_model_dir = model_dir.joinpath('binarised')\n",
    "    !mkdir -p {base_model_dir}\n",
    "    !mkdir -p {tuned_model_dir}\n",
    "    !mkdir -p {binarised_model_dir}\n",
    "\n",
    "    base_moses_ini = base_model_dir.joinpath('model/moses.ini')\n",
    "    base_phrase_table = base_model_dir.joinpath('model/phrase-table.gz')\n",
    "    base_reordering_table = base_model_dir.joinpath('model/reordering-table.wbe-msd-bidirectional-fe.gz')\n",
    "\n",
    "    tuned_moses_ini = tuned_model_dir.joinpath('moses.ini')\n",
    "\n",
    "    binarised_moses_ini = binarised_model_dir.joinpath('moses.ini')\n",
    "    binarised_phrase_table = binarised_model_dir.joinpath('phrase-table')\n",
    "    binarised_reordering_table = binarised_model_dir.joinpath('reordering-table')\n",
    "\n",
    "    # train\n",
    "    train_moses(base_model_dir, TRAIN_IN, FROM, TO, LM, lm_order=LM_ORDER)\n",
    "\n",
    "    # tune\n",
    "    tune_moses(tuned_model_dir, VAL_IN, VAL_OUT, base_moses_ini)\n",
    "\n",
    "    # binarise\n",
    "    !mkdir -p {binarised_model_dir}\n",
    "\n",
    "    lm_out = binarised_model_dir.joinpath('lm.blm')\n",
    "\n",
    "    prepare_binarisation(tuned_moses_ini, \n",
    "                         LM,\n",
    "                         lm_out, \n",
    "                         binarised_moses_ini, \n",
    "                         binarised_phrase_table, \n",
    "                         binarised_reordering_table)\n",
    "    binarise_phrase_table(base_phrase_table, binarised_phrase_table)\n",
    "    binarise_reordering_table(base_reordering_table, binarised_reordering_table)\n",
    "\n",
    "    # translate\n",
    "    translated = binarised_model_dir.joinpath(f'translated.{FROM}')\n",
    "\n",
    "    translate_corpus(binarised_moses_ini, TEST_IN, translated)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "is-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tail -f /work/is-en-improved/base/training.out\n"
     ]
    }
   ],
   "source": [
    "train_tune_eval(LM = c.read(p, EN, PARICE, TRAIN, LM),\n",
    "                LM_ORDER = 3,\n",
    "                FROM = 'is',\n",
    "                TO = 'en',\n",
    "                MODIFIER = 'improved',\n",
    "                TRAIN_IN = c.read(p, IS, PARICE, TRAIN, LENGTH).with_suffix(''),\n",
    "                VAL_IN = c.read(p, IS, PARICE, VAL, FINAL),\n",
    "                VAL_OUT = c.read(p, EN, PARICE, VAL, FINAL),\n",
    "                TEST_IN = c.read(p, IS, PARICE, TEST, FINAL),\n",
    "                TEST_OUT = c.read(p, EN, PARICE, TEST, FINAL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "en-is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tune_eval(LM = c.read(p, IS, RMH, TRAIN, CAT, LM),\n",
    "                LM_ORDER = 3,\n",
    "                FROM = 'en',\n",
    "                TO = 'is',\n",
    "                MODIFIER = 'improved',\n",
    "                TRAIN_IN = c.read(p, IS, PARICE, TRAIN, LENGTH).with_suffix(''),\n",
    "                VAL_IN = c.read(p, EN, PARICE, VAL, FINAL),\n",
    "                VAL_OUT = c.read(p, IS, PARICE, VAL, FINAL),\n",
    "                TEST_IN = c.read(p, EN, PARICE, TEST, FINAL),\n",
    "                TEST_OUT = c.read(p, IS, PARICE, TEST, FINAL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['perl: warning: Setting locale failed.', 'perl: warning: Please check that your locale settings:', '\\tLANGUAGE = \"en_US:en\",', '\\tLC_ALL = (unset),', '\\tLC_CTYPE = \"C.UTF-8\",', '\\tLANG = \"en_US.UTF-8\"', '    are supported and installed on your system.', 'perl: warning: Falling back to the standard locale (\"C\").', 'Use of uninitialized value $length_reference in numeric eq (==) at /opt/moses/scripts/generic/multi-bleu.perl line 148.', 'BLEU = 0, 0/0/0/0 (BP=0, ratio=0, hyp_len=0, ref_len=0)']\n",
      "en: • 6 km for category 2 motorcycle ( engine capacity ≥ 150 cc , vmax @lt@ 130 km / h ) ,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TEST_OUT = c.read(p, EN, PARICE, TEST, FINAL)\n",
    "FROM = 'is'\n",
    "TO = 'en'\n",
    "MODIFIER = 'improved'\n",
    "model_dir = working_dir.joinpath(f'{FROM}-{TO}-{MODIFIER}')\n",
    "binarised_model_dir = model_dir.joinpath('binarised')\n",
    "translated = binarised_model_dir.joinpath(f'translated.{FROM}')\n",
    "print(eval_translation(TEST_OUT, translated))\n",
    "print(*c.corpora_peek((TEST_OUT, translated)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To correct comparison we need to map the translated BPE text to the normal test and compare with `test/final.en`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_detokenize_bpe(sentence):\n",
    "    pieces = sentence.split(\" \")\n",
    "    return ''.join(pieces).replace('▁', ' ').strip()\n",
    "\n",
    "def corpus_detokenize_bpe(path, out_path):\n",
    "    with path.open() as f_in, out_path.open('w+') as f_out:\n",
    "        for line in f_in:\n",
    "            f_out.write(sent_detokenize_bpe(line)+'\\n')\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated_detokenized = c.corpus_create_path(translated, 'translated_detokenized')\n",
    "corpus_detokenize_bpe(translated, translated_detokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['perl: warning: Setting locale failed.', 'perl: warning: Please check that your locale settings:', '\\tLANGUAGE = \"en_US:en\",', '\\tLC_ALL = (unset),', '\\tLC_CTYPE = \"C.UTF-8\",', '\\tLANG = \"en_US.UTF-8\"', '    are supported and installed on your system.', 'perl: warning: Falling back to the standard locale (\"C\").', 'It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.', 'BLEU = 47.69, 68.9/50.6/41.8/35.4 (BP=1.000, ratio=1.015, hyp_len=38406, ref_len=37857)']\n",
      "is: • 6 km fyrir bifhjól í flokki 2 ( slagrými hreyfils ≥ 150 cc , vmax @lt@ 130 km / klukkustund ) ,\n",
      " en: • 6 km fyrir bifhjól í flokki 2 ( slagrými hreyfils ≥ 150 cc , vmax @lt@ 130 km / klukkustund ) .\n",
      " is: enska aðgerð varðandi sameiginlega fræðslu e - liður 1. málsgrein 5. grein .\n",
      " en: enska aðgerð varðandi sameiginlega fræðslu e - lið 1. málsgrein 5. grein\n",
      " is: mælingar á reykþéttni útblásturslofts við hröðun ( frá hægagangi og upp í marksnúningshraða , án álags ) .\n",
      " en: mælingar á reykþéttni útblásturslofts við hröðun ( frá hægagangi án álags upp .\n",
      " is: aðrir tengivagnar\n",
      " en: aðrir eftirvagnar og festivagnar\n",
      " is: ég er með matareitrun .\n",
      " en: ég er með matareitrun .\n",
      " is: perlur á stærð við kókoshnetur .\n",
      " en: perlur á stærð við kókoshnetur .\n",
      " is: þetta markmið skal einkum mæla í fjölgun aðildarríkja sem fella inn samræmdar nálganir við gerð viðbúnaðaráætlana sinna .\n",
      " en: þetta markmið skal einkum mæla í fjölgun aðildarríkja samþætta samræmdar nálganir á viðbúnaðaráætlana þeirra .\n",
      " is: allir út , við erum í vanda .\n",
      " en: við höfum allir átt við vandamál að stríða .\n",
      " is: við jafnvægi var þéttni sonidegibs í húð 6 - falt hærri en í plasma .\n",
      " en: jafnvægi sonidegibs á vettvangi sprakk fyrir 6 - falt hærri en í plasma .\n",
      " is: einkennin komu fram allt frá einum degi til nokkurra mánaða eftir að meðferð hófst .\n",
      " en: tími þar til einkenna var frá einum degi eða nokkrum mánuðum eftir að meðferð hófst .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(eval_translation(TEST_OUT, translated_detokenized))\n",
    "print(*c.corpora_peek((TEST_OUT, translated_detokenized)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo\n",
    "Þýða einhvern texta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_en_is(moses_ini, sentence):\n",
    "    sentence = c.sent_process_v1(sentence, c.Lang.EN)\n",
    "    !echo \"{sentence}\" | {os.getenv('MOSESDECODER')}/bin/moses -f {moses_ini}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined parameters (per moses.ini or switch):\n",
      "\tconfig: /work/en-is-rmh/binarised/moses.ini \n",
      "\tdistortion-limit: 6 \n",
      "\tfeature: UnknownWordPenalty WordPenalty PhrasePenalty PhraseDictionaryCompact name=TranslationModel0 num-features=4 path=/work/en-is-rmh/binarised/phrase-table input-factor=0 output-factor=0 LexicalReordering name=LexicalReordering0 num-features=6 type=wbe-msd-bidirectional-fe-allff input-factor=0 output-factor=0 path=/work/en-is-rmh/binarised/reordering-table Distortion KENLM name=LM0 factor=0 path=/work/en-is-rmh/binarised/lm.blm order=3 \n",
      "\tinput-factors: 0 \n",
      "\tmapping: 0 T 0 \n",
      "\tthreads: 10 \n",
      "\tweight: LexicalReordering0= 0.0169919 0.229923 0.142056 0.00709025 -0.0357982 0.136943 Distortion0= -0.0411258 LM0= 0.0329771 WordPenalty0= -0.117491 PhrasePenalty0= -0.0976637 TranslationModel0= 0.0113354 0.00836338 0.1168 0.0054414 UnknownWordPenalty0= 1 \n",
      "line=UnknownWordPenalty\n",
      "FeatureFunction: UnknownWordPenalty0 start: 0 end: 0\n",
      "line=WordPenalty\n",
      "FeatureFunction: WordPenalty0 start: 1 end: 1\n",
      "line=PhrasePenalty\n",
      "FeatureFunction: PhrasePenalty0 start: 2 end: 2\n",
      "line=PhraseDictionaryCompact name=TranslationModel0 num-features=4 path=/work/en-is-rmh/binarised/phrase-table input-factor=0 output-factor=0\n",
      "FeatureFunction: TranslationModel0 start: 3 end: 6\n",
      "line=LexicalReordering name=LexicalReordering0 num-features=6 type=wbe-msd-bidirectional-fe-allff input-factor=0 output-factor=0 path=/work/en-is-rmh/binarised/reordering-table\n",
      "Initializing Lexical Reordering Feature..\n",
      "FeatureFunction: LexicalReordering0 start: 7 end: 12\n",
      "line=Distortion\n",
      "FeatureFunction: Distortion0 start: 13 end: 13\n",
      "line=KENLM name=LM0 factor=0 path=/work/en-is-rmh/binarised/lm.blm order=3\n",
      "FeatureFunction: LM0 start: 14 end: 14\n",
      "Loading UnknownWordPenalty0\n",
      "Loading WordPenalty0\n",
      "Loading PhrasePenalty0\n",
      "Loading LexicalReordering0\n",
      "Loading Distortion0\n",
      "Loading LM0\n",
      "Loading TranslationModel0\n",
      "Created input-output object : [5.572] seconds\n",
      "Translating: \n",
      "Line 1: Initialize search took 0.000 seconds total\n",
      "Line 1: Collecting options took 0.000 seconds at moses/Manager.cpp Line 141\n",
      "Line 1: Search took 0.000 seconds\n",
      "Line 1: Decision rule took 0.000 seconds total\n",
      "Line 1: Additional reporting took 0.000 seconds totalTranslating: this is a proper english \n",
      "Line 1: Translation took 0.001 seconds total\n",
      "sentence , and we can have learnt a better phrase model \n",
      "Line 0: Initialize search took 0.001 seconds total\n",
      "Line 0: Collecting options took 1.093 seconds at moses/Manager.cpp Line 141\n",
      "Line 0: Search took 0.204 seconds\n",
      "þetta er enskan setningunni og við getum hafa lært betri setning fyrirmynd \n",
      "BEST TRANSLATION: þetta er enskan setningunni og við getum hafa lært betri setning fyrirmynd [1111111111111111]  [total=-4.199] core=(0.000,-12.000,8.000,-16.979,-27.442,-6.050,-24.238,-1.645,0.000,0.000,-1.874,0.000,0.000,0.000,-106.908)  \n",
      "\n",
      "BEST TRANSLATION: []  [total=0.000] core=(0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000)  \n",
      "Line 0: Decision rule took 0.000 seconds total\n",
      "Line 0: Additional reporting took 0.000 seconds total\n",
      "Line 0: Translation took 1.298 seconds total\n",
      "Name:moses\tVmPeak:10184564 kB\tVmRSS:945952 kB\tRSSMax:9128312 kB\tuser:5.362\tsys:1.775\tCPU:7.137\treal:7.161\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "sentence = \"This is a proper English sentence, and we can have learnt a better phrase model\"\n",
    "print(translate_en_is(binarised_model_dir.joinpath('moses.ini'), sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_is_en(moses_ini, sentence):\n",
    "    sentence = c.sent_process_v1(sentence, c.Lang.IS)\n",
    "    !echo \"{sentence}\" | {os.getenv('MOSESDECODER')}/bin/moses -f {moses_ini}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined parameters (per moses.ini or switch):\n",
      "\tconfig: /work/is-en/binarised/moses.ini \n",
      "\tdistortion-limit: 6 \n",
      "\tfeature: UnknownWordPenalty WordPenalty PhrasePenalty PhraseDictionaryCompact name=TranslationModel0 num-features=4 path=/work/is-en/binarised/phrase-table input-factor=0 output-factor=0 LexicalReordering name=LexicalReordering0 num-features=6 type=wbe-msd-bidirectional-fe-allff input-factor=0 output-factor=0 path=/work/is-en/binarised/reordering-table Distortion KENLM name=LM0 factor=0 path=/work/is-en/binarised/lm-en.blm order=3 \n",
      "\tinput-factors: 0 \n",
      "\tmapping: 0 T 0 \n",
      "\tthreads: 14 \n",
      "\tweight: LexicalReordering0= 0.114192 0.0158818 0.0202684 0.083186 0.0208785 0.197803 Distortion0= 0.0160226 LM0= 0.0632488 WordPenalty0= -0.204654 PhrasePenalty0= -0.0417258 TranslationModel0= 0.0177732 0.00823355 0.188931 0.00720186 UnknownWordPenalty0= 1 \n",
      "line=UnknownWordPenalty\n",
      "FeatureFunction: UnknownWordPenalty0 start: 0 end: 0\n",
      "line=WordPenalty\n",
      "FeatureFunction: WordPenalty0 start: 1 end: 1\n",
      "line=PhrasePenalty\n",
      "FeatureFunction: PhrasePenalty0 start: 2 end: 2\n",
      "line=PhraseDictionaryCompact name=TranslationModel0 num-features=4 path=/work/is-en/binarised/phrase-table input-factor=0 output-factor=0\n",
      "FeatureFunction: TranslationModel0 start: 3 end: 6\n",
      "line=LexicalReordering name=LexicalReordering0 num-features=6 type=wbe-msd-bidirectional-fe-allff input-factor=0 output-factor=0 path=/work/is-en/binarised/reordering-table\n",
      "Initializing Lexical Reordering Feature..\n",
      "FeatureFunction: LexicalReordering0 start: 7 end: 12\n",
      "line=Distortion\n",
      "FeatureFunction: Distortion0 start: 13 end: 13\n",
      "line=KENLM name=LM0 factor=0 path=/work/is-en/binarised/lm-en.blm order=3\n",
      "FeatureFunction: LM0 start: 14 end: 14\n",
      "Loading UnknownWordPenalty0\n",
      "Loading WordPenalty0\n",
      "Loading PhrasePenalty0\n",
      "Loading LexicalReordering0\n",
      "Loading Distortion0\n",
      "Loading LM0\n",
      "Loading TranslationModel0\n",
      "Created input-output object : [1.002] seconds\n",
      "Translating: \n",
      "Line 1: Initialize search took Translating: 0.000 seconds total\n",
      "ég man ekkiLine 1: Collecting options took  eftir0.000 seconds at moses/Manager.cpp Line  neinum141\n",
      " góðum myndum nýlega \n",
      "Line 1: Search took 0.000 seconds\n",
      "Line 0: Initialize search took 0.001 seconds total\n",
      "Line 1: Decision rule took 0.000 seconds total\n",
      "Line 1: Additional reporting took 0.000 seconds total\n",
      "Line 1: Translation took 0.001 seconds total\n",
      "Line 0: Collecting options took 0.292 seconds at moses/Manager.cpp Line 141\n",
      "Line 0: Search took 0.059 seconds\n",
      "i can ' t even remember some good pictures recently \n",
      "BEST TRANSLATION: i can ' t even remember some good pictures recently [11111111]  [total=-2.430] core=(0.000,-10.000,3.000,-3.181,-21.657,-2.845,-23.124,-1.415,0.000,0.000,-1.022,0.000,0.000,0.000,-50.052)  \n",
      "\n",
      "BEST TRANSLATION: []  [total=0.000] core=(0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000)  \n",
      "Line 0: Decision rule took 0.000 seconds total\n",
      "Line 0: Additional reporting took 0.000 seconds total\n",
      "Line 0: Translation took 0.352 seconds total\n",
      "Name:moses\tVmPeak:2102776 kB\tVmRSS:486448 kB\tRSSMax:979400 kB\tuser:1.074\tsys:0.427\tCPU:1.502\treal:1.498\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Ég man ekki eftir neinum góðum myndum nýlega \"\n",
    "print(translate_is_en(working_dir.joinpath('is-en/binarised').joinpath('moses.ini'), sentence))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
