{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ParIce + RMH + EN mono - map/pre-process\n",
    "Í þessu reikniriti forvinnum við öll gögnin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The location of en-mono to read\n",
    "en_mono_dir = '/work/haukurpj/data/filtered/en-monolingual'\n",
    "\n",
    "# The location of where to write the results\n",
    "en_mono_target_dir = '/work/haukurpj/data/mapped/en-monolingual'\n",
    "\n",
    "# The location of rmh to read\n",
    "is_mono_dir = '/work/haukurpj/data/filtered/risamalheild'\n",
    "\n",
    "# The location of where to write the results\n",
    "is_mono_target_dir = '/work/haukurpj/data/mapped/risamalheild'\n",
    "\n",
    "# The location of parice to read\n",
    "parice_dir = '/work/haukurpj/data/filtered/Parice1.0'\n",
    "\n",
    "# The location of where to write the results\n",
    "parice_target_dir = '/work/haukurpj/data/mapped/Parice1.0'\n",
    "\n",
    "THREADS = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "en_mono_dir = pathlib.Path(en_mono_dir)\n",
    "en_mono_target_dir = pathlib.Path(en_mono_target_dir)\n",
    "is_mono_dir = pathlib.Path(is_mono_dir)\n",
    "is_mono_target_dir = pathlib.Path(is_mono_target_dir)\n",
    "parice_dir = pathlib.Path(parice_dir)\n",
    "parice_target_dir = pathlib.Path(parice_target_dir)\n",
    "assert en_mono_dir.exists()\n",
    "assert is_mono_dir.exists()\n",
    "assert parice_dir.exists()\n",
    "if not en_mono_target_dir.exists():\n",
    "    en_mono_target_dir.mkdir()\n",
    "if not is_mono_target_dir.exists():\n",
    "    is_mono_target_dir.mkdir()\n",
    "if not parice_target_dir.exists():\n",
    "    parice_target_dir.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from frontend import bulk as b\n",
    "from frontend import core as c\n",
    "from frontend import definitions as d\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "URI = re.compile(r\"((http(s)?:\\/\\/)|(www)|([-a-zA-Z0-9:%_\\+.~#?&/=]+?@))+([-a-zA-Z0-9@:%_\\+.~#?&/=]+)\", re.IGNORECASE)\n",
    "URI_SIMPLE = re.compile(r\"([-a-zA-Z0-9@:%_\\+.~#?&/=]+?)(\\.is|\\.com)\", re.IGNORECASE)\n",
    "\n",
    "reg = c.regexp\n",
    "tok = c.tokenize\n",
    "low = c.lowercase_normalize\n",
    "second_reg = [\n",
    "        d.SUB_PIPE,\n",
    "        d.SUB_LT,\n",
    "        d.SUB_GT,\n",
    "        d.SUB_BRACKET_OPEN,\n",
    "        d.SUB_BRACKET_CLOSE,\n",
    "        d.SUB_FIX_PLACEHOLDERS\n",
    "    ]\n",
    "first_reg = [\n",
    "        {\n",
    "            'pattern': URI,\n",
    "            'repl': '_uri_'\n",
    "        },\n",
    "        {\n",
    "            'pattern': URI_SIMPLE,\n",
    "            'repl': '_uri_'\n",
    "        },\n",
    "        d.SUB_EMPTY_BRACKETS\n",
    "    ]\n",
    "\n",
    "def preprocess_sent(sent, lang, method):\n",
    "    sent = reg(sent, first_reg)\n",
    "    sent = tok(sent, lang, method=method)\n",
    "    sent = low(sent)\n",
    "    sent = reg(sent, second_reg)\n",
    "    return sent + '\\n'\n",
    "\n",
    "def bulk_process_sent(p_in, p_out, function):\n",
    "    lang = b._lang(p_in)\n",
    "    if str(lang) == 'is':\n",
    "        method = \"shallow\"\n",
    "    else:\n",
    "        method = \"moses\"\n",
    "    with p_in.open() as f_in, p_out.open('w+') as f_out:\n",
    "        with ProcessPoolExecutor(max_workers=THREADS) as executor:\n",
    "            results = tqdm(executor.map(\n",
    "                function,\n",
    "                f_in,\n",
    "                chunksize=6000))\n",
    "            for result in results:\n",
    "                f_out.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71137920it [32:24, 36582.69it/s]\n",
      "3256945it [01:16, 42844.44it/s]\n",
      "3256945it [01:57, 27678.60it/s]\n",
      "2000it [00:00, 5472.98it/s]\n",
      "2000it [00:00, 2899.21it/s]\n",
      "1930it [00:00, 3375.47it/s]\n",
      "1930it [00:00, 2411.62it/s]\n",
      "1963it [00:00, 3910.51it/s]\n",
      "1963it [00:00, 2621.60it/s]\n",
      "2059it [00:00, 9533.33it/s]\n",
      "2059it [00:00, 3354.13it/s]\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "#bulk_process_sent(en_mono_dir.joinpath('mono.en'), \n",
    "#                  en_mono_target_dir.joinpath('mono.en'),\n",
    "#                  partial(preprocess_sent, method='moses', lang=c.Lang.EN))\n",
    "bulk_process_sent(is_mono_dir.joinpath('rmh.is'),\n",
    "                  is_mono_target_dir.joinpath('rmh.is'),\n",
    "                  partial(preprocess_sent, method='shallow', lang=c.Lang.IS))\n",
    "bulk_process_sent(parice_dir.joinpath('train.is'),\n",
    "                  parice_target_dir.joinpath('train.is'),\n",
    "                  partial(preprocess_sent, method='shallow', lang=c.Lang.IS))\n",
    "bulk_process_sent(parice_dir.joinpath('train.en'),\n",
    "                  parice_target_dir.joinpath('train.en'),\n",
    "                  partial(preprocess_sent, method='moses', lang=c.Lang.EN))\n",
    "bulk_process_sent(parice_dir.joinpath('dev.is'),\n",
    "                  parice_target_dir.joinpath('dev.is'),\n",
    "                  partial(preprocess_sent, method='shallow', lang=c.Lang.IS))\n",
    "bulk_process_sent(parice_dir.joinpath('dev.en'),\n",
    "                  parice_target_dir.joinpath('dev.en'),\n",
    "                  partial(preprocess_sent, method='moses', lang=c.Lang.EN))\n",
    "bulk_process_sent(parice_dir.joinpath('test-ees.is'),\n",
    "                  parice_target_dir.joinpath('test-ees.is'),\n",
    "                  partial(preprocess_sent, method='shallow', lang=c.Lang.IS))\n",
    "bulk_process_sent(parice_dir.joinpath('test-ees.en'),\n",
    "                  parice_target_dir.joinpath('test-ees.en'),\n",
    "                  partial(preprocess_sent, method='moses', lang=c.Lang.EN))\n",
    "bulk_process_sent(parice_dir.joinpath('test-ema.is'),\n",
    "                  parice_target_dir.joinpath('test-ema.is'),\n",
    "                  partial(preprocess_sent, method='shallow', lang=c.Lang.IS))\n",
    "bulk_process_sent(parice_dir.joinpath('test-ema.en'),\n",
    "                  parice_target_dir.joinpath('test-ema.en'),\n",
    "                  partial(preprocess_sent, method='moses', lang=c.Lang.EN))\n",
    "bulk_process_sent(parice_dir.joinpath('test-opensubtitles.is'),\n",
    "                  parice_target_dir.joinpath('test-opensubtitles.is'),\n",
    "                  partial(preprocess_sent, method='shallow', lang=c.Lang.IS))\n",
    "bulk_process_sent(parice_dir.joinpath('test-opensubtitles.en'),\n",
    "                  parice_target_dir.joinpath('test-opensubtitles.en'),\n",
    "                  partial(preprocess_sent, method='moses', lang=c.Lang.EN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-notebook]",
   "language": "python",
   "name": "conda-env-.conda-notebook-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
