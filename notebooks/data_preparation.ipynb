{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "Í þessu reikniriti er tekið við gögnum eftir fyrstu samhæfinu og unnin frekar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter, OrderedDict\n",
    "import os\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import re\n",
    "from pprint import pprint\n",
    "import importlib\n",
    "from typing import List, Sequence\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import frontend.core as c\n",
    "import frontend.bulk as b\n",
    "import frontend.definitions as d\n",
    "\n",
    "c.THREADS = 6\n",
    "\n",
    "working_dir = pathlib.Path('/work/haukurpj')\n",
    "data_dir = working_dir.joinpath('data')\n",
    "processing_dir = working_dir.joinpath('process')\n",
    "p = processing_dir\n",
    "parice_dir = data_dir.joinpath('parice')\n",
    "rmh_dir = data_dir.joinpath('risamalheild')\n",
    "train_dir = p.joinpath('train')\n",
    "test_dir = p.joinpath('test')\n",
    "dev_dir = p.joinpath('dev')\n",
    "\n",
    "IS = c.Lang.IS\n",
    "EN = c.Lang.EN\n",
    "\n",
    "RMH, PARICE = 'rmh', 'parice'\n",
    "EES, EMA, OPENSUB = 'ees', 'ema', 'opensubtitles'\n",
    "TRAIN, DEV, TEST = 'train-dev', 'dev', 'test'\n",
    "\n",
    "langs = [IS, EN]\n",
    "splits = [TRAIN, DEV, TEST]\n",
    "\n",
    "SENT_FIX = 'sent_fix'\n",
    "PROCESSED = 'processed'\n",
    "LOWER = 'lower'\n",
    "\n",
    "FINAL = 'final'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "URI = re.compile(r\"((http(s)?:\\/\\/)|(www)|([-a-zA-Z0-9:%_\\+.~#?&/=]+?@))+([-a-zA-Z0-9@:%_\\+.~#?&/=]+)\", re.IGNORECASE)\n",
    "URI_SIMPLE = re.compile(r\"([-a-zA-Z0-9@:%_\\+.~#?&/=]+?)(\\.is|\\.com)\", re.IGNORECASE)\n",
    "\n",
    "def preprocess_sent(sent, lang, method):\n",
    "    # print(sent)\n",
    "    \n",
    "    regexps = [\n",
    "        {\n",
    "            'pattern': URI,\n",
    "            'repl': '_uri_'\n",
    "        },\n",
    "        {\n",
    "            'pattern': URI_SIMPLE,\n",
    "            'repl': '_uri_'\n",
    "        },\n",
    "        d.SUB_EMPTY_BRACKETS,\n",
    "        {\n",
    "            'pattern': re.compile(r\"(\\d+(.\\d+)?)(mgr|gr|skv|og|eða|til|með|janúar|febrúar|mars|apríl|maí|júní|júlí|ágúst|september|október|nóvember|desember)\", re.IGNORECASE),\n",
    "            'repl': r\"\\1. \\3\",\n",
    "        },\n",
    "        {\n",
    "            'pattern': re.compile(r\"(skv)(?=[^.])\"),\n",
    "            'repl': r\"\\1.\"\n",
    "        },\n",
    "        {\n",
    "            'pattern': re.compile(r\"(\\d+(.\\d+)?\\. )(mgr|gr)(?=[^.])\", re.IGNORECASE),\n",
    "            'repl': r\"\\1\\3. \"\n",
    "        },\n",
    "    ]\n",
    "    sent = c.regexp(sent, regexps)\n",
    "    sent = c.tokenize(sent, lang, method=method)\n",
    "    sent = c.lowercase_normalize(sent)\n",
    "    regexps = [\n",
    "        d.SUB_PIPE,\n",
    "        d.SUB_LT,\n",
    "        d.SUB_GT,\n",
    "        d.SUB_BRACKET_OPEN,\n",
    "        d.SUB_BRACKET_CLOSE,\n",
    "        d.SUB_FIX_PLACEHOLDERS\n",
    "    ]\n",
    "    sent = c.regexp(sent, regexps)\n",
    "    return sent\n",
    "\n",
    "def bulk_preprocess_sent(p_in, p_out):\n",
    "    lang = b._lang(p_in)\n",
    "    if lang == IS:\n",
    "        method = \"shallow\"\n",
    "    else:\n",
    "        method = \"moses\"\n",
    "    b.in_parallel(p_in, \n",
    "                  p_out,\n",
    "                  c.THREADS,\n",
    "                  partial(preprocess_sent, lang=lang, method=method),\n",
    "                  chunksize = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def simple_preprocess_sent(sent, lang, method):\n",
    "    sent = c.tokenize(sent, lang, method=method)\n",
    "    sent = c.lowercase_normalize(sent)\n",
    "    regexps = [\n",
    "        d.SUB_PIPE,\n",
    "        d.SUB_LT,\n",
    "        d.SUB_GT,\n",
    "        d.SUB_BRACKET_OPEN,\n",
    "        d.SUB_BRACKET_CLOSE,\n",
    "    ]\n",
    "    sent = c.regexp(sent, regexps)\n",
    "    return sent\n",
    "\n",
    "def lowercase_sent(sent, lang):\n",
    "    return c.lowercase_normalize(sent)\n",
    "\n",
    "def bulk_lower_sent(p_in, p_out):\n",
    "    lang = b._lang(p_in)\n",
    "    if lang == IS:\n",
    "        method = \"shallow\"\n",
    "    else:\n",
    "        method = \"moses\"\n",
    "    b.in_parallel(p_in, \n",
    "                  p_out,\n",
    "                  c.THREADS,\n",
    "                  partial(lowercase_sent, lang=lang),\n",
    "                  chunksize = 10000)\n",
    "    \n",
    "def bulk_preprocess_sent(p_in, p_out):\n",
    "    lang = b._lang(p_in)\n",
    "    if lang == IS:\n",
    "        method = \"shallow\"\n",
    "    else:\n",
    "        method = \"moses\"\n",
    "    b.in_parallel(p_in, \n",
    "                  p_out,\n",
    "                  c.THREADS,\n",
    "                  partial(simple_preprocess_sent, lang=lang, method=method),\n",
    "                  chunksize = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1930/1930 [00:00<00:00, 3650.37it/s]\n",
      "100%|██████████| 1930/1930 [00:00<00:00, 2653.68it/s]\n",
      "100%|██████████| 1963/1963 [00:00<00:00, 5399.93it/s]\n",
      "100%|██████████| 1963/1963 [00:00<00:00, 2896.50it/s]\n",
      "100%|██████████| 2059/2059 [00:00<00:00, 11307.56it/s]\n",
      "100%|██████████| 2059/2059 [00:00<00:00, 3219.93it/s]\n"
     ]
    }
   ],
   "source": [
    "#bulk_preprocess_sent(b.read(train_dir, IS, TRAIN), b.write(train_dir, IS, PROCESSED))\n",
    "#bulk_preprocess_sent(b.read(train_dir, EN, TRAIN), b.write(train_dir, EN, PROCESSED))\n",
    "#bulk_preprocess_sent(b.read(dev_dir, IS, DEV), b.write(dev_dir, IS, PROCESSED))\n",
    "#bulk_preprocess_sent(b.read(dev_dir, EN, DEV), b.write(dev_dir, EN, PROCESSED))\n",
    "bulk_preprocess_sent(b.read(working_dir, IS, EES), b.write(working_dir, IS, EES, PROCESSED))\n",
    "bulk_preprocess_sent(b.read(working_dir, EN, EES), b.write(working_dir, EN, EES, PROCESSED))\n",
    "bulk_preprocess_sent(b.read(working_dir, IS, EMA), b.write(working_dir, IS, EMA, PROCESSED))\n",
    "bulk_preprocess_sent(b.read(working_dir, EN, EMA), b.write(working_dir, EN, EMA, PROCESSED))\n",
    "bulk_preprocess_sent(b.read(working_dir, IS, OPENSUB), b.write(working_dir, IS, OPENSUB, PROCESSED))\n",
    "bulk_preprocess_sent(b.read(working_dir, EN, OPENSUB), b.write(working_dir, EN, OPENSUB, PROCESSED))\n",
    "#bulk_preprocess_sent(b.read(p, IS, RMH, SENT_FIX), b.write(p, IS, RMH, FINAL, TOK_LOW))\n",
    "#bulk_preprocess_sent(b.read(p, EN, 'mono'), b.write(p, EN, 'mono', FINAL, TOK_LOW))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the test set we will use to compare with - the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1930/1930 [00:00<00:00, 106276.92it/s]\n",
      "100%|██████████| 1930/1930 [00:00<00:00, 134847.11it/s]\n",
      "100%|██████████| 1963/1963 [00:00<00:00, 120394.50it/s]\n",
      "100%|██████████| 1963/1963 [00:00<00:00, 520312.11it/s]\n",
      "100%|██████████| 2059/2059 [00:00<00:00, 215955.79it/s]\n",
      "100%|██████████| 2059/2059 [00:00<00:00, 246477.31it/s]\n"
     ]
    }
   ],
   "source": [
    "OPENSUB = 'opensubtitles'\n",
    "bulk_lower_sent(b.read(working_dir, IS, EES), b.write(working_dir, IS, EES, LOWER))\n",
    "bulk_lower_sent(b.read(working_dir, EN, EES), b.write(working_dir, EN, EES, LOWER))\n",
    "bulk_lower_sent(b.read(working_dir, IS, EMA), b.write(working_dir, IS, EMA, LOWER))\n",
    "bulk_lower_sent(b.read(working_dir, EN, EMA), b.write(working_dir, EN, EMA, LOWER))\n",
    "bulk_lower_sent(b.read(working_dir, IS, OPENSUB), b.write(working_dir, IS, OPENSUB, LOWER))\n",
    "bulk_lower_sent(b.read(working_dir, EN, OPENSUB), b.write(working_dir, EN, OPENSUB, LOWER))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now done processing the val, test, EN mono and RMH datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resumption of the session\r\n",
      "i declare resumed the session of the european parliament adjourned on friday , 15 december 2000 .\r\n",
      "statements by the president\r\n",
      "ladies and gentlemen , on saturday , as you know , an earthquake struck central america once again , with tragic consequences .\r\n",
      "this is an area which has already been seriously affected on a number of occasions since the beginning of the twentieth century .\r\n",
      "the latest , provisional , figures for victims in el salvador are already very high .\r\n",
      "there are 350 people dead , 1 200 people missing , the area is completely devastated and thousands of homes have been destroyed throughout the country .\r\n",
      "the european union has already shown its solidarity by sending a rescue team to the area , whilst financial assistance from the union and member states has been , or is in the process of being , released and i am able to inform you that some groups in the european parliament have requested that this issue be included in the debate on topical and urgent subjects of major importance on thursday .\r\n",
      "however , i should like to inform you that i have , of course , on behalf of the european union , expressed our sincere condolences and deepest sympathy to the president of el salvador in the tragedy which has struck his country .\r\n",
      "i would ask you , as a mark of respect for the victims and for the immense suffering of their families , to observe a minute ' s silence .\r\n"
     ]
    }
   ],
   "source": [
    "!head {b.read(p, EN, 'mono', FINAL, TOK_LOW)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fjarlægja slæmar línur\n",
    "Núna búum við til safn af \"íslenskum\" orðum frá RMH og förum yfir íslenskar setningar í ParIce og athugum hversu stórt hlutfall af orðunum í ParIce-IS eru í safninu okkar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "655511\n"
     ]
    }
   ],
   "source": [
    "is_counter_1 = b.token_counter(b.read(p, IS, PARICE, TRAIN, PROCESSED))\n",
    "print(len(is_counter_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6073000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmh_counter = b.token_counter(b.read(p, IS, RMH, PROCESSED))\n",
    "is_words = set(rmh_counter.keys())\n",
    "len(is_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "# Setting the chunksize higher is better here.\n",
    "print(b.CHUNKSIZE)\n",
    "b.CHUNKSIZE = 50000\n",
    "print(b.CHUNKSIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3540825/3540825 [02:30<00:00, 23545.40it/s] \n"
     ]
    }
   ],
   "source": [
    "skip_lines = b.get_drop_lines(b.read(p, IS, PARICE, TRAIN, PROCESSED),\n",
    "                              [c.REGEXP_SUB['CRYLLIC'][0],\n",
    "                               c.REGEXP_SUB['GREEK'][0],\n",
    "                               c.REGEXP_SUB['UNKNOWN-CHARS'][0]\n",
    "                              ],\n",
    "                              is_words,\n",
    "                              keep_ratio=0.8,\n",
    "                              normalize=True,\n",
    "                              keep_sent_length=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new fraction 0.04822237755325387\n"
     ]
    }
   ],
   "source": [
    "lines = [number for number, fraction, line in skip_lines]\n",
    "print(\"new fraction\", (1 - (b.info(b.read(p, IS, PARICE, TRAIN, PROCESSED))[2] - len(lines))/b.info(b.read(p, IS, PARICE, TRAIN, PROCESSED))[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.drop_lines(b.read(p, IS, PARICE, TRAIN, PROCESSED),\n",
    "             b.write(p, IS, PARICE, TRAIN, FINAL),\n",
    "             lines_in=lines)\n",
    "b.drop_lines(b.read(p, EN, PARICE, TRAIN, PROCESSED),\n",
    "             b.write(p, EN, PARICE, TRAIN, FINAL),\n",
    "             lines_in=lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "580166\n",
      "0.11494086292983641\n"
     ]
    }
   ],
   "source": [
    "is_counter_2 = b.token_counter(b.read(p, IS, PARICE, TRAIN, FINAL))\n",
    "print(len(is_counter_2))\n",
    "print(1-(len(is_counter_2)/(len(is_counter_1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-notebook]",
   "language": "python",
   "name": "conda-env-.conda-notebook-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
